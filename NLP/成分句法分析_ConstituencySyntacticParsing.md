
æˆåˆ†åˆ†æï¼š

Ambiguity

score the tree

generative

discrimitive


## ç›®å½•

- [ç®€ä»‹](https://chatgpt.com/c/67ff1808-b25c-8012-807c-3b381e6835dc#%E7%AE%80%E4%BB%8B)
    
- [æˆåˆ†å¥æ³•åŸºç¡€æ¦‚å¿µ](https://chatgpt.com/c/67ff1808-b25c-8012-807c-3b381e6835dc#%E6%88%90%E5%88%86%E5%8F%A5%E6%B3%95%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5)
    
- [æˆåˆ†å¥æ³•åˆ†æçš„å½¢å¼åŒ–æè¿°](https://chatgpt.com/c/67ff1808-b25c-8012-807c-3b381e6835dc#%E6%88%90%E5%88%86%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E7%9A%84%E5%BD%A2%E5%BC%8F%E5%8C%96%E6%8F%8F%E8%BF%B0)
    
- [å¸¸ç”¨ç®—æ³•](https://chatgpt.com/c/67ff1808-b25c-8012-807c-3b381e6835dc#%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95)
    
    - [CKYç®—æ³•](https://chatgpt.com/c/67ff1808-b25c-8012-807c-3b381e6835dc#CKY%E7%AE%97%E6%B3%95)
        
    - [ç©·ä¸¾æœç´¢](https://chatgpt.com/c/67ff1808-b25c-8012-807c-3b381e6835dc#%E7%A9%B7%E4%B8%BE%E6%90%9C%E7%B4%A2)
        
    - [é€’å½’ä¸‹é™åˆ†æ](https://chatgpt.com/c/67ff1808-b25c-8012-807c-3b381e6835dc#%E9%80%92%E5%BD%92%E4%B8%8B%E9%99%8D%E5%88%86%E6%9E%90)
        
- [åº”ç”¨åœºæ™¯ä¸æŒ‘æˆ˜](https://chatgpt.com/c/67ff1808-b25c-8012-807c-3b381e6835dc#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B8%8E%E6%8C%91%E6%88%98)
    
- [å‘å±•ä¸å·¥å…·](https://chatgpt.com/c/67ff1808-b25c-8012-807c-3b381e6835dc#%E5%8F%91%E5%B1%95%E4%B8%8E%E5%B7%A5%E5%85%B7)
    


å¸¸è§è¯æ±‡è¡¨

| ç¼©å†™         | å«ä¹‰                                     | è¯´æ˜                               |
| ---------- | -------------------------------------- | -------------------------------- |
| **S**      | Sentence                               | å¥å­                               |
| **NP**     | Noun Phrase                            | åè¯çŸ­è¯­ï¼Œä¾‹å¦‚ â€œthe catâ€                |
| **VP**     | Verb Phrase                            | åŠ¨è¯çŸ­è¯­ï¼Œä¾‹å¦‚ â€œis sleepingâ€            |
| **PP**     | Prepositional Phrase                   | ä»‹è¯çŸ­è¯­ï¼Œä¾‹å¦‚ â€œin the houseâ€           |
| **ADJP**   | Adjective Phrase                       | å½¢å®¹è¯çŸ­è¯­ï¼Œä¾‹å¦‚ â€œvery beautifulâ€        |
| **ADVP**   | Adverb Phrase                          | å‰¯è¯çŸ­è¯­ï¼Œä¾‹å¦‚ â€œvery quicklyâ€           |
| **SBAR**   | Subordinate Clause                     | ä»å¥ï¼ˆå¼•å¯¼è¯å¦‚ "that", "if", "because"ï¼‰ |
| **WHNP**   | WH-Noun Phrase                         | ä»¥ wh-word å¼€å¤´çš„åè¯çŸ­è¯­ï¼Œä¾‹å¦‚ â€œwhat timeâ€ |
| **WHADJP** | WH-Adjective Phrase                    | ä¾‹å¦‚ â€œhow bigâ€                     |
| **WHADVP** | WH-Adverb Phrase                       | ä¾‹å¦‚ â€œwhereâ€, â€œhowâ€                |
| **WHPP**   | WH-Prepositional Phrase                | ä¾‹å¦‚ â€œin what wayâ€                 |
| **PRT**    | Particle                               | å°å“è¯ï¼ˆå¦‚â€œgive upâ€ä¸­çš„â€œupâ€ï¼‰            |
| **INTJ**   | Interjection                           | æ„Ÿå¹è¯ï¼Œä¾‹å¦‚ â€œohâ€, â€œwowâ€               |
| **CONJP**  | Conjunction Phrase                     | è¿è¯çŸ­è¯­ï¼Œä¾‹å¦‚ â€œas well asâ€             |
| **LST**    | List marker                            | åˆ—è¡¨ç¬¦å·ï¼Œå¦‚ "1.", "A."                |
| **NAC**    | Not A Constituent                      | ä¸æ˜¯ä¸€ä¸ªæ ‡å‡†æˆåˆ†çš„çŸ­è¯­ï¼Œç”¨äºä¿®é¥°åè¯çš„å…¶ä»–ç»“æ„          |
| **NX**     | Noun phrase with internal modification | ç‰¹æ®Šçš„åè¯ç»“æ„ï¼Œç”¨äºåµŒå¥—çŸ­è¯­                   |
| **QP**     | Quantifier Phrase                      | æ•°é‡çŸ­è¯­ï¼Œå¦‚ â€œmore than fiveâ€          |
| **RRC**    | Reduced Relative Clause                | ç®€åŒ–å…³ç³»ä»å¥ï¼Œå¦‚ â€œthe man seenâ€          |
| **UCP**    | Unlike Coordinated Phrase              | ä¸åŒç±»å‹çš„çŸ­è¯­å¹¶åˆ—ï¼Œå¦‚â€œold and in the wayâ€  |
| **X**      | Unknown/uncategorized                  | éæ ‡å‡†ç»“æ„çš„é€šç”¨å ä½ç¬¦                      |



## 1. Introduction to Syntax and Parsing

- **Syntax**: Studies the rules that govern sentence structure; independent of meaning.
    
- A syntactically correct sentence can be semantically meaningless: _"Colorless green ideas sleep furiously."_
    

## 2. Syntactic Parsing Types

### 2.1 Constituency Parsing (Phrase Structure)

- Represents sentences as hierarchical phrase structures.
    
- Non-leaf nodes represent **constituents**:
    - `S`: Sentence
    - `NP`: Noun Phrase
    - `VP`: Verb Phrase
    - `PP`: Prepositional Phrase
    - `ADJP`: Adjective Phrase
        

### 2.2 Dependency Parsing

- Represents binary relations (head-dependent) between words.
    

## 3. Parsing Goals and Scoring

- Assign a score/probability to each parse tree.
    
- **Disambiguation**: Choose the most probable parse among many.

> [!note] Ambiguity
>A sentence is ambiguous if it has more than one possible parse tree

- Scoring method: decompose parse into parts, score each part, then sum or multiply.

## Generative Parsing and Discriminative Parsing 
#### Generative Parsing
$$
\hat{t} = \arg\max_{t \in \mathcal{T}_x} S(t, x)
$$
We model joint generation of sentence $x$ and parse tree $t$ 

#### Discriminative Parsing 

$$
\hat{t} = \arg\max_{t \in \mathcal{T}_x} P(t \mid x)
$$
We model conditional probability of parse tree $t$ given sentence $x$, so we can take into account the complete sentence  $x$ when scoring parse tree $t$

## 4. Parsing Methods
Independent Assumption: assume parsing of a part of the sentence is independent of the other part in the sentence i.e. $s[i,j]$ is independent of $s[k,l]$  

- Assume independent: **Dynamic Programming (DP)**:
    
    - Span-based parsing (e.g., CYK algorithm)
    - grammar-based parsing
    - Global optimization
        
- Do not assume independent: Local search(**Greedy / Beam Search**):
    
    - Transition-based parsing
        
    - Local optimization
        

## 5. Learning Approaches

### 5.1 Supervised Learning

- Requires a treebank (e.g., Penn TreeBank, Chinese Treebank).
    
### 5.2 Unsupervised Learning

- Grammar Induction from raw text.
    
- Requires EM algorithm and inside-outside algorithm.
    

## 6. Parser Evaluation

- Represent parse as tuples: `(label, i, j)`
    ![[Pasted image 20250422123852.png|475]]
- **Precision, Recall, F1** calculated using gold and predicted tuples.
    ![[Pasted image 20250422123944.png|525]]
- [Macro-Micro-F1](../æœºå™¨å­¦ä¹ _MachineLearning/æ„å»ºæœºå™¨å­¦ä¹ ç®—æ³•_BuildingMachineLearningAlgorithms#F1åˆ†æ•°_F1Score)

    

## 7. Span-Based Parsing
- Binary tree only
- Tree score = sum of constituent scores   $s(t) = \sum_{(i, j, l) \in t} s(i, j, l)$
	![[Pasted image 20250422124711.png]]

   - çº¦æŸæ¡ä»¶ï¼šå½“ $l \neq S$ æ—¶ï¼Œ$s(1,n,l)=-\infty$
   - ç›®æ ‡å‡½æ•°ï¼š$\arg \max \sum_{(i,j,l)\in t} s(i,j,l)$  

#### span scoring
- discriminative 

based on neural network: **åŒä»¿å°„ï¼ˆBiaffineï¼‰æ‰“åˆ†å™¨**

$$
s(i, j, l) = \text{Biaffine}_l(r_i, r_j) = 
\begin{bmatrix} r_i \\ 1 \end{bmatrix}^T 
W_l 
\begin{bmatrix} r_j \\ 1 \end{bmatrix}
$$

- **$r_i$**ï¼šç¬¬ $i$ ä¸ªè¯çš„ embeddingï¼Œé€šå¸¸æ¥è‡ªäº BiLSTMã€Transformer ç­‰æ¨¡å‹ã€‚
- **$r_j$**ï¼šç¬¬ $j$ ä¸ªè¯çš„ embeddingã€‚
- **$W_l$**ï¼šweight matrix, ä¸“é—¨ä¸ºæ ‡ç­¾ `l` è®¾è®¡ã€‚
- **$[r_i; 1]$** å’Œ **$[r_j; 1]$**ï¼šè¡¨ç¤ºå‘ embedding å‘é‡é™„åŠ ä¸€ä¸ªå¸¸æ•° $1$ï¼Œç”¨äºæ•æ‰åç½®é¡¹ï¼ˆbiasï¼‰

#### parsing(CKY)

1. **Input**: A sentence of length $n$
2. **Neural span scorer** provides scores $s(i, j, l)$ for all valid spans $0 \le i < j \le n$ and labels $l$
3. Use dynamic programming to fill a chart `dp[i][j]`, which stores:
   - The best score for span $(i, j)$
   - The best label $l^*$ for that span
   - The best split point $k^*$


Let $s_{\text{best}}(i, j)$ be the best score for span $(i, j)$. 

- Preprocessing:
$$
s(i, j) = \max_{l} s(i, j, l)
$$

- Base case (length 1 spans):

$$
s_{\text{best}}(i, i) = s(i, i)
$$
- Recursion (for length > 1 spans):

$$
s_{\text{best}}(i, j) = s(i, j) + \max_{k=i+1}^{j-1} \left( s_{\text{best}}(i, k) + s_{\text{best}}(k, j) \right) 
$$
	- $k$ : split point
	-  `max` chooses best way to **split** the span $(i, j)$ into left and right children.
![[Pasted image 20250422130703.png|200]]

â±ï¸ Time Complexity
- Time: $O(n^3 \cdot L)$, where $n$ is the sentence length and $L$ is the number of labels
- Space: $O(n^2 \cdot L)$


#### Supervised Learning 
- $\theta$ : $W_l$ (+word embedding)

We aim to **maximize the conditional likelihood** of the gold parse tree $t^*$ given an input sentence $x$:

 **Objective Function**

$$
P(t \mid x) = \frac{\exp s(t)}{Z(x)} = \frac{\exp \sum_{(i,j,l) \in t} s(i,j,l)}{Z(x)}=\frac{\prod_{(i,j,l)\in t} \exp s(i,j,l)}{Z(x)}
$$

$$
Z(x) = \sum_{t}\exp s(t)
$$
- We use `exp` to ensure positive.

Where:
- $s(t)$: total score of the tree (sum of span scores)
- $Z(x) = \sum_{t} \exp s(t)$: **partition function** (é…åˆ†å‡½æ•°ï¼Œå½’ä¸€åŒ–å› å­)

> This is a **Conditional Random Field (CRF)** approach, globally normalizing across all possible trees.

---

 ğŸ” Inside Algorithm (CRF Partition Function)

To compute the partition function $Z(x)$, we use a **dynamic programming algorithm** called the **Inside Algorithm**, which is a soft version of CKY.

**Inside Score Definition**

Let $\alpha(i, j)$ denote the inside score for span $(i, j)$:

$$
\alpha(i, j) = \sum_{t \in \mathcal{T}_x(i,j)} \exp s(t)
$$

Where $\mathcal{T}_x(i,j)$ is the set of all possible subtrees spanning positions $i$ to $j$.

The final partition function is:
$$
Z(x) = \alpha(1, n)
$$


- **Preprocessing Step**

Compute unstructured span scores:
$$
s'(i, j) = \sum_{l} \exp s(i, j, l)
$$

- **Base Case**: spans of a single token

$$
\alpha(i, i) =  s'(i, i)
$$

- **Recursive Case**
For spans longer than one token:

$$
\alpha(i, j) = s'(i, j) \cdot \sum_k \left[ \alpha(i, k) \cdot \alpha(k+1, j) \right]
$$
proof:

$$
\alpha(i, j)
= \sum_{k} \sum_{A} \sum_{t_1 \in \mathcal{T}_x(i,k)} \sum_{t_2 \in \mathcal{T}_x(k+1,j)} \exp (s(i, j, A) +s(t_1) +s(t_2))
$$
$$
\alpha(i, j)
= \sum_{k} \sum_{A} \sum_{t_1 \in \mathcal{T}_x(i,k)} \sum_{t_2 \in \mathcal{T}_x(k+1,j)} \exp s(i, j, A) \cdot \exp s(t_1) \cdot \exp s(t_2)
$$

Group the exponential terms:

$$
= \sum_{A} \exp s(i, j, A) \cdot \sum_{k} \left( \sum_{t_1 \in \mathcal{T}_x(i,k)} \exp s(t_1) \cdot \sum_{t_2 \in \mathcal{T}_x(k+1,j)} \exp s(t_2) \right)
$$

Use the definition of inside scores $\alpha(i,k)$ and $\alpha(k+1,j)$:

$$
= \sum_{A} \exp s(i, j, A) \cdot \sum_{k} \left( \alpha(i,k) \cdot \alpha(k+1,j) \right)
$$

Define the **pre-aggregated label score**:

$$
s'(i,j) = \sum_{A} \exp s(i,j,A)
$$


> ğŸ§  This is like CKY, but instead of taking the **max**, we take the **sum** over all subtreesâ€”analogous to the **Forward algorithm** in HMMs.

---

##### âš–ï¸ Discriminative Methods Summary

- Maximize the **log-likelihood** of the correct tree:

$$
\log P(t^* \mid x) = s(t^*) - \log Z(x)
$$

- Use **stochastic gradient descent (SGD)** to optimize.
	$$
\mathcal{L}(\theta) = \log P(t^* \mid x; \theta) = s_\theta(t^*) - \log Z_\theta(x)
$$
	Loss func:
$$
\mathcal{J}(\theta) = -\mathcal{L}(\theta)
$$
	Use $\theta$ to score parse tree and then compute loss and then update
- $Z(x)$ is computed using the **Inside Algorithm**.
- Alternative: use **margin-based loss** (e.g., structured hinge loss) if exact likelihood is too expensive.


## 8. Context-Free Grammar (CFG)

The term **â€œcontext-freeâ€** means:

> Each production rule replaces a **single non-terminal** with some sequence of terminals and/or non-terminals, **regardless of context**.

That is, the rule $A \rightarrow \beta$ can be applied **whenever** you see $A$, without needing to know **what comes before or after** it.

### Generative Grammars
- The classical way of modeling syntax.
- **Context-Free Grammars (CFGs)**:
  - Also known as *phrase structure grammars*.
  - One of the simplest and most basic grammar formalisms.

---

### components
- A set $\Sigma$ of **terminals** (words)
- A set $N$ of **nonterminals** (constituent classes, types of phrases)
- A **start symbol** $S \in N$
- A set $R$ of **production rules**:
  - Each rule describes how a nonterminal can produce a sequence of terminals and/or nonterminals

---

### Example

#### Grammar Rule Examples
```
S  â†’ NP VP           // I want a morning flight
NP â†’ Pronoun          // I
   | Proper-Noun       // Los Angeles
   | Det Nominal       // a flight
Nominal â†’ Nominal Noun // morning flight
        | Noun         // flights
VP â†’ Verb             // do
    | Verb NP         // want a flight
    | Verb NP PP      // leave Boston in the morning
    | Verb PP         // leave on Thursday
PP â†’ Preposition NP   // from Los Angeles
```

#### Lexicon (Terminal Expansions)
```
Noun        â†’ flights | breeze | trip | morning
Verb        â†’ is | prefer | like | need | want | fly
Adjective   â†’ cheapest | non-stop | first | latest | other | direct
Pronoun     â†’ me | I | you | it
Proper-Noun â†’ Alaska | Baltimore | Los Angeles | Chicago | United | American
Determiner  â†’ the | a | an | this | these | that
Preposition â†’ from | to | on | near
Conjunction â†’ and | or | but
```

---

### Sentence Generation with CFG
- A grammar can generate a string by:
  - Starting from a string that contains only the start symbol $S$
  - Recursively applying production rules
  - Continuing until the string contains only terminal symbols
- This defines the **grammatical structure (parse tree)** of the sentence

![[Pasted image 20250422141740.png|425]]
### Probabilistic Context-Free Grammars (PCFG)
- Also known as **stochastic CFGs (SCFGs)**
- Each production rule is associated with a **probability**:
  $$
  \alpha \rightarrow \beta : P(\alpha \rightarrow \beta \mid \alpha)
  $$

- The **probability of a parse tree** is the product of the probabilities of all rules used to generate the tree.

#### Example:
```
S  â†’ NP VP          [0.80]
S  â†’ Aux NP VP      [0.15]
S  â†’ VP             [0.05]
NP â†’ Pronoun        [0.35]
   | Proper-Noun      [0.30]
   | Det Nominal      [0.20]
   | Nominal          [0.15]
Nominal â†’ Noun       [0.75]
        | Nominal Noun [0.20]
        | Nominal PP   [0.05]
VP â†’ Verb            [0.35]
    | Verb NP         [0.20]
    | Verb NP PP      [0.10]
    | Verb PP         [0.15]
    | Verb NP NP      [0.05]
    | VP PP           [0.15]
PP â†’ Preposition NP  [1.00]
```
![[Pasted image 20250422142015.png|225]]
**Parse Tree Probability**:

$$
P(T) = 0.05 \times 0.20 \times 0.20 \times 0.75 \times 0.30 \times 0.60 \times 0.10 \times 0.40 = 2.2 \times 10^{-6}
$$

---

### Weighted Context-Free Grammars (WCFG)

- Each rule has a **weight** instead of a probability.
- These weights are usually **non-negative real numbers**, not necessarily summing to 1.
- The **score of a derivation tree $T$** is the **product of the weights of the rules** used:


$$
\text{Score}(T) = \prod_{\text{rule used}} w(\text{rule})
$$


So in **form**, itâ€™s the **same as PCFG**, just with **weights** instead of probabilities.

#### Key Comparisons:
- PCFG $\approx$ HMM
- WCFG $\approx$ CRF

#### Rule Weights:
- Can be computed from the input sentence using **anchored features**, such as:
  - Rule identity $A \rightarrow BC$
  - Words at the span boundary: $w_{p-1}, w_p, w_q, w_{q+1}$
  - Words at the split point: $w_d, w_{d+1}$

#### Neural WCFG:
- Weights can be produced by a **neural network**, using:
  - Embeddings of nonterminals
  - Word embeddings at the span boundary and split point

### Parsing Algorithm
Use CYK algorithm 




## 9. CYK Parsing

- Requires CNF (Chomsky Normal Form).
    - CNF require the Rule set $R$  should only contain two types rule: $A\to BC$  or $A\to \text{terminal}$ 
    - Convert a rule base to CNF: if $A\to BCD$, convert it to $A\to XD$ and $X\to BC$
- CYK is a Bottom-up DP.
    
- Fill chart by combining smaller spans.

![[Pasted image 20250425233951.png|375]]

- å…·ä½“ç®—æ³•è§ppt 62-82é¡µ
### Probabilistic CYK

- Associate probabilities with nonterminals in spans.
    
- Base: use rule probability for terminal.
    
- Recursion: `P(A, i, j) = max(P(A->BC) * P(B, i, k) * P(C, k, j))`
- Ambiguity: choose the max probability
![[Pasted image 20250426004832.png|450]]

![[Pasted image 20250426004853.png|450]]
![[Pasted image 20250426005019.png|450]]

### CYK for WCFG 


- **Score of a parse tree**:
  
$$
\text{Score}(T) = \prod_{\text{rules used}} w(\text{rule})
$$

  or in **log-space**:
  
$$
\log \text{Score}(T) = \sum_{\text{rules used}} \log w(\text{rule})
$$


#### Standard Space
**Base Case**:
For a terminal token $w_i$ and a rule $A \rightarrow w_i$:

$$
\text{score}_A[i, i] = w(A \rightarrow w_i)
$$

**Recursive Case**:
For each span $(i, j)$, for all rules $A \rightarrow B\ C$, and for all split points $k$ between $i$ and $j$:

$$
\text{score}_A[i, j] = \max_{B,C,k} \left[ w(A \rightarrow B C) \cdot \text{score}_B[i, k] \cdot \text{score}_C[k+1, j] \right]
$$


- This computes the **maximum-score parse** rooted at $A$ covering span $x_i \dots x_j$
- Uses **multiplication** of rule weights 


#### In log-space

We adapt the **CYK algorithm** for WCFG by replacing probabilities with **log-weights**.

**Base Case**:
For a terminal word $w_i$ and rule $A \rightarrow w_i$:

$$
s_{\text{best}}(i, i, A) = \log w(A \rightarrow w_i)
$$


**Recursive Case**:
For a non-terminal span $A \rightarrow B\ C$, covering substring $x_i \dots x_j$:

$$
s_{\text{best}}(i, j, A) = \max_{B, C, k} \left[ \log w(A \rightarrow B C) + s_{\text{best}}(i, k, B) + s_{\text{best}}(k, j, C) \right]
$$


- $i < k < j$ is the split point
- Uses **max-sum** dynamic programming (like Viterbi)
- Replaces PCFG probabilities with **arbitrary weights**

### CYK in Span-based vs. PCFG Parsing

#### CYK for PCFG (in log space)

- **Base case**:
  
$$
s_{\text{best}}(i, i, A) := \log P_{A, i-1, i} = \log P(A \rightarrow w_i)
$$


- **Recursion**:
  
$$
s_{\text{best}}(i, j, A) := \log P_{A, i, j}
$$

  
$$
= \max_{B,C,k} \left[ \log P(A \rightarrow BC) + s_{\text{best}}(i, k, B) + s_{\text{best}}(k, j, C) \right]
$$


####  Span-based CYK

- **Base case**:
  
$$
s_{\text{best}}(i, i) = s(i, i)
$$


- **Recursion**:
  
$$
s_{\text{best}}(i, j) = s(i, j) + \max_k \left[ s_{\text{best}}(i, k) + s_{\text{best}}(k+1, j) \right]
$$




## CFG Learning

### âš™ï¸ Generative Methods

#### ğŸ“ Learning PCFGs

- Learn **probabilistic CFGs** from treebanks.
	-   Parameter: the rule probabilities
- Use **Maximum Likelihood Estimation (MLE)**.
	- Estimate rule probabilities from counts:
	  
	$$
	P(\text{rule}) = \frac{\text{count(rule in treebank)}}{\text{count(parent nonterminal)}}
	$$
	
##### ğŸ“Š Example:

| Rule             | Count | Probability |
|------------------|--------|-------------|
| VP â†’ Verb        | 20     | 0.20        |
| VP â†’ Verb NP     | 40     | 0.40        |
| VP â†’ Verb NP NP  | 25     | 0.25        |
| VP â†’ Verb PP     | 15     | 0.15        |

##### âš ï¸ Limitations of MLE

- F1 score often **< 80** on evaluation.
- Main issue: **standard nonterminals are not expressive enough** (e.g., "NP", "VP" too generic).

---

### âš™ï¸ Discriminative Methods

#### ğŸ§® Learning a WCFG (Weighted CFG)

- Similar to span-based parsing.
- No need for rule probabilities to sum to 1.
- Weights can depend on features or neural networks.

##### ğŸ¯ Objective

- Maximize the **conditional likelihood**:
  
$$
P(t^* \mid x) = \frac{\prod_{r \in (t,x)} W(r \mid x)}{Z(x)}
$$

  where:
  - $t^*$: gold parse tree
  - $W(r \mid x)$: score/weight of rule $r$
  - $Z(x)$: partition function over all trees for input $x$

- $Z(x)$ is computed using the **Inside Algorithm**.

##### âš™ï¸ Optimization

- Typically done with **Stochastic Gradient Descent (SGD)**.
- Alternative: **margin-based loss** (similar to structured SVM).

---

### ğŸš« Unsupervised Learning (Grammar Induction)

#### ğŸ” Goal

- Learn grammar rules and parameters **without parse annotations**.
- Only uses raw sentences (sometimes with POS tags).

#### ğŸ›  Two Subtasks

1. **Structure Search**  
   - Search for a good set of grammar rules.  
   - Still an open problem for real data.

2. **Parameter Learning**  
   - Fix a rule set (e.g., by assuming all possible unary/binary rules).
   - Learn rule weights/probabilities from data.

---

#### ğŸ“š Parameter Learning via EM

- Use **Expectation-Maximization (EM)** to maximize marginal likelihood:
  
$$
P(x) = \sum_{t \in T_x} P(t)
$$


#### ğŸ” EM Algorithm

- **E-step**:  
  Compute expected rule counts using the **Inside-Outside algorithm**.

- **M-step**:  
  Normalize expected counts to update rule probabilities.

- Repeat until convergence.

#### âš¡ Alternatives

- Directly optimize $P(x)$ with **gradient descent**.
- Inside probabilities computed via **inside algorithm**.


## 10. Inside Algorithm 

The **Inside Algorithm** is a dynamic programming method used to compute the **partition function** $Z(x)$ in **probabilistic parsing** (e.g., PCFG or WCFG), which sums over all possible parse trees of an input sentence.

### ğŸ§  Motivation

In discriminative or probabilistic CFG learning, we want to compute:


$$
Z(x) = \sum_{t \in T_x} \exp(s(t))
$$


Where:
- $T_x$: all valid parse trees for sentence $x$
- $s(t)$: score of a tree $t$
- $Z(x)$: normalizing factor (partition function)

Computing $Z(x)$ directly by enumeration is intractable, so we use the **Inside Algorithm**.

---

### ğŸ§® Inside Score Definition

The **inside score** for a span $(i, j)$ is defined as:


$$
\alpha(i, j) = \sum_{t \in T_x(i, j)} \exp(s(t))
$$


Where:
- $T_x(i, j)$: all subtree structures rooted at any non-terminal covering span $(i, j)$

We want to compute the final value:

$$
Z(x) = \alpha(1, n)
$$

Where $n$ is the length of the sentence.

---

### âš™ï¸ Algorithm Steps

#### ğŸ”¹ Preprocessing

Compute:

$$
s'(i, j) = \sum_{l} \exp(s(i, j, l))
$$

for all labels $l$ spanning $(i, j)$

#### ğŸ”¹ Base Case

For single-token spans:

$$
\alpha(i, i) = s'(i, i) = \sum_l \exp(s(i, i, l))
$$


#### ğŸ”¹ Recursive Case

For larger spans:

$$
\alpha(i, j) = s'(i, j) \cdot \sum_{k=i}^{j-1} \alpha(i, k) \cdot \alpha(k+1, j)
$$


- $k$: split point between $i$ and $j$
- $s'(i, j)$: score for combining subtrees across span

### ğŸ¤ Relationship to Other Algorithms

| Algorithm               | Function               |
| ----------------------- | ---------------------- |
| CYK (Viterbi)           | Finds best parse (max) |
| Inside Algorithm        | Sums over all parses   |
| Forward Algorithm (HMM) | Special case of Inside |
| Viterbi Algorithm (HMM) | Special case of CYK    |

#### Why the relationship is looked like above?

##### Analogy: HMM vs. PCFG

| Concept in HMM             | Equivalent in PCFG                    |
|----------------------------|----------------------------------------|
| State sequence             | Derivation tree (parse tree)           |
| Transition probabilities   | Rule probabilities                    |
| Emission probabilities     | Terminal rule probabilities           |
| Forward algorithm          | Inside algorithm                      |


Both algorithms compute the **total probability** of generating a sequence by **summing over all possible latent structures**:

- **HMM Forward Algorithm**: sums over all possible **state sequences**.
- **PCFG Inside Algorithm**: sums over all possible **parse trees**.

Formally:
-  HMM Forward Algorithm


$$
\alpha_t(s) = \sum_{s'} \alpha_{t-1}(s') \cdot P(s \mid s') \cdot P(x_t \mid s)
$$

	- $\alpha_t(s)$: total probability of being in state $s$ at time $t$
	- Recursive computation based on combining probabilities over state transitions and emissions.

- PCFG Inside Algorithm


$$
\alpha(i, j, A) = \sum_{A \rightarrow B C} \sum_{k=i}^{j-1} P(A \rightarrow B C) \cdot \alpha(i, k, B) \cdot \alpha(k+1, j, C)
$$


	- $\alpha(i, j, A)$: total probability of generating the span $x_i \dots x_j$ from non-terminal $A$
	- Summing over **all ways to split and derive** using PCFG rules.

##### Why HMM is a Special Case

- An **HMM** can be seen as a **right-branching linear CFG** where:
  - Each state emits one word (like a terminal rule).
  - Transitions model rule expansions.
- The HMMâ€™s **forward algorithm** is essentially doing **inside computation** on a **linear tree structure**.

## 11. Transition-Based Parsing

### Core Ideas
- A parse tree is represented as a linear sequence of **transitions**.
- **Parser Configuration**:
  - **Buffer $B$**: Unprocessed words of the input sentence.
  - **Stack $S$**: Parse tree under construction.
- **Transition**: A simple action transferring one configuration to another.

### Transition-Based Parsing Process

- Initial Configuration
	- Buffer $B$ contains the full input sentence.
	- Stack $S$ is empty.

- During Parsing
	- A classifier decides which transition to apply next.
	- No backtracking is involved.

- Final Configuration
	- Buffer $B$ is empty.
	- Stack $S$ contains the complete parse tree.

### Transition Operations (Bottom-Up, Sagae 2005)

>Assume CNF grammar

- **SHIFT**: Move front word from buffer $B$ to stack $S$.
- **REDUCE-X**: 
  $$
  A = \text{pop}(S), \quad B = \text{pop}(S), \quad \text{push}(S, X \rightarrow BA)
  $$
  Where $A, B, X$ are nonterminals.
- **UNARY-Y**: 
  $$
  w = \text{pop}(S), \quad \text{push}(S, Y \rightarrow w)
  $$
  $w$: terminal, $Y$: nonterminal.

### Classifier-Based Action Scoring

- At each step, choose among:
  - $\{\text{SHIFT}, \text{REDUCE-X}, \text{UNARY-Y}\}$
  - $2|Y|+1$ kinds actions
- Train a classifier using features from:
  - Stack $S$, Buffer $B$, and transition history $H$.
- Use neural networks:
  - LSTM/Transformer over $B$ and $H$
  - Recursive neural nets over $S$  i.e.combine word embeddings with bottom-up 

### Training Data: Oracle Transitions
In transition-based parsing, an `oracle` is a component that provides the correct action to take at each step of the parsing process, given a gold-standard parse tree.
- Convert a gold parse tree into a sequence of **(configuration, correct transition)** pairs.

Example:
```text
<Bâ‚, Sâ‚, SHIFT>
<Bâ‚‚, Sâ‚‚, UNARY-Det>
<Bâ‚ƒ, Sâ‚ƒ, SHIFT>
<Bâ‚„, Sâ‚„, UNARY-NP>
```

### Limitations and Solutions

#### Flaw in Standard Oracle
- Only correct configurations are used in training. During inference, misclassifications can lead to **unseen configurations**.

#### Dynamic Oracle
- Introduce random errors to generate incorrect configurations.
- Use rule-based transitions to convert back to gold state quickly.
- Train classifier to predict these corrections.

### Action Selection Strategies

- **Greedy**: Select highest scoring action.
- **Beam Search**: Maintain multiple top-$k$ hypotheses.

---

### Time Complexity

Given $L$ words in sentence:
- $L$ SHIFTS
- $L$ UNARY-Xs
- $(L - 1)$ REDUCE-Xs
- Total:
  $$
  3L - 1 \quad \text{(Linear time)}
  $$

### Transition-Based Parsing Systems

- Bottom-up(post-order traverse)
- Top-down(pre-order traverse)
- In-order(in-order traverse)

## DP vs. Transition-Based Parsing

| Criteria        | Dynamic Programming (DP)   | Transition-Based             |
| --------------- | -------------------------- | ---------------------------- |
| Type            | Span-based, grammar-based  | Transition-sequence-based    |
| Assumption      | Independence between spans | No independence assumption   |
| Optimization    | Global (DP)                | Local (greedy/beam)          |
| Time Complexity | Cubic                      | Linear                       |
| Performance     | Traditionally superior     | Competitive w/ neural models |


## 12. Modern Methods

- **Seq2Seq parsing** : treat parsing as translation.
    
- **Sequence labeling**: encode tree structure in tags.
    
- **Syntactic distance**: Predict syntactic distance between left & right at each possible split point. Recursively split the sentence following the descending order of syntactic distances.
    
- **Top-down splitting**: pointer networks for recursive splitting.
    

## 13. Summary Table

| Method           | Optimization         | Complexity | Notes                            |
| ---------------- | -------------------- | ---------- | -------------------------------- |
| Span-based (CYK) | Global (DP)          | O(n^3)     | Requires independence assumption |
| Transition-based | Local (greedy/beam)  | O(n)       | No independence assumption       |
| PCFG             | Generative model     | O(n^3)     | Requires CNF                     |
| WCFG             | Discriminative model | O(n^3)     | Can use neural features          |

























































































































## ç®€ä»‹

æˆåˆ†å¥æ³•åˆ†æï¼ˆConstituency Parsingï¼‰æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ä¸€é¡¹åŸºæœ¬ä»»åŠ¡ï¼Œæ—¨åœ¨å°†å¥å­åˆ†è§£ä¸ºå…·æœ‰å±‚æ¬¡ç»“æ„çš„ç»„æˆæˆåˆ†ï¼Œå¹¶ä»¥**å¥æ³•æ ‘**ï¼ˆparse treeï¼‰å½¢å¼è¡¨ç¤ºå¥å­çš„ç»“æ„ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%E6%98%AF%E6%8C%87%E5%AF%B9%E8%BE%93%E5%85%A5%E7%9A%84%E5%8D%95%E8%AF%8D%E5%BA%8F%E5%88%97%EF%BC%88%E4%B8%80%E8%88%AC%E4%B8%BA%E5%8F%A5%E5%AD%90%EF%BC%89%E5%88%A4%E6%96%AD%E5%85%B6%E6%9E%84%E6%88%90%E6%98%AF%E5%90%A6%E5%90%88%E4%B9%8E%E7%BB%99%E5%AE%9A%E7%9A%84%E8%AF%AD%E6%B3%95%EF%BC%8C%E5%88%86%E6%9E%90%E5%87%BA%E5%90%88%E4%B9%8E%E8%AF%AD%E6%B3%95%E7%9A%84%E5%8F%A5%E5%AD%90%E7%9A%84%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E3%80%82)) ([Parse tree - Wikipedia](https://en.wikipedia.org/wiki/Parse_tree#:~:text=The%20constituency,sentence%20John%20hit%20the%20ball))ã€‚åœ¨å¥æ³•æ ‘ä¸­ï¼Œå†…éƒ¨èŠ‚ç‚¹ç”±**éç»ˆç»“ç¬¦**ï¼ˆnon-terminalï¼‰ç±»åˆ«æ ‡æ³¨ï¼Œå¦‚åè¯çŸ­è¯­(NP)ã€åŠ¨è¯çŸ­è¯­(VP)ç­‰ï¼›å¶èŠ‚ç‚¹ç”±å¥å­çš„**ç»ˆç»“ç¬¦**ï¼ˆterminalï¼‰æ ‡æ³¨ï¼Œå³åŸå§‹è¯æ±‡ ([Parse tree - Wikipedia](https://en.wikipedia.org/wiki/Parse_tree#:~:text=The%20constituency,sentence%20John%20hit%20the%20ball))ã€‚é€šè¿‡æˆåˆ†å¥æ³•åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥è¯†åˆ«å¥å­ä¸­çš„çŸ­è¯­è¾¹ç•Œå’Œå±‚æ¬¡ç»“æ„ï¼Œå°†åŠŸèƒ½ç›¸ä¼¼çš„è¯ç»„åˆæˆæ›´å¤§çš„çŸ­è¯­å•å…ƒã€‚ä¾‹å¦‚ï¼ŒæŠŠè¯­æ³•ä½œç”¨ç›¸åŒçš„ä¸€ç»„è¯ç»„åˆæˆåè¯çŸ­è¯­ï¼ˆnoun phraseï¼‰ï¼Œå¯åœ¨å¥ä¸­å……å½“ä¸»è¯­æˆ–å®¾è¯­ç­‰æˆåˆ† ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E6%88%90%E5%88%86))ã€‚æˆåˆ†å¥æ³•åˆ†æè¿‡ç¨‹å°±æ˜¯é€æ­¥åˆ†æè¯å¦‚ä½•ç»„æˆçŸ­è¯­ã€çŸ­è¯­å¦‚ä½•ç»„æˆæ›´å¤æ‚çš„çŸ­è¯­ï¼Œæœ€ç»ˆç»„æˆå®Œæ•´å¥å­çš„è¿‡ç¨‹ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E6%88%90%E5%88%86))ã€‚

æˆåˆ†å¥æ³•åˆ†æåœ¨NLPä¸­å…·æœ‰é‡è¦æ„ä¹‰ã€‚å®ƒæ­ç¤ºäº†å¥å­çš„å†…éƒ¨ç»“æ„å’Œç»„æˆï¼Œæœ‰åŠ©äºè®¡ç®—æœºå¯¹æ–‡æœ¬è¿›è¡Œæ›´æ·±å±‚æ¬¡çš„ç†è§£å’Œå¤„ç† ([æ·±å…¥è§£æSyntaxNetï¼šè‡ªç„¶è¯­è¨€ç†è§£çš„åˆ©å™¨-æ˜“æºAIèµ„è®¯ | ä¸‡ç»´æ˜“æº](https://www.showapi.com/news/article/66f80f104ddd79f11a397dd7#:~:text=%E9%99%85%E5%BA%94%E7%94%A8%E3%80%82%20,1%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E6%98%AF%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E4%B8%80%EF%BC%8C%E5%AE%83%E8%B4%9F%E8%B4%A3%E5%B0%86%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E6%88%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8F%AF%E4%BB%A5%E7%90%86%E8%A7%A3%E5%92%8C%E6%93%8D%E4%BD%9C%E7%9A%84%E5%BD%A2%E5%BC%8F%E3%80%82%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E9%80%9A%E8%BF%87%E5%AF%B9))ã€‚å¥æ³•æ ‘æä¾›äº†ä¸»è°“å®¾ç­‰å¥å­æˆåˆ†ä¹‹é—´çš„å±‚æ¬¡å…³ç³»ï¼Œè¿™ç§ç»“æ„åŒ–ä¿¡æ¯æ˜¯è¿æ¥**è¯æ³•åˆ†æ**ï¼ˆlexical analysisï¼‰ä¸**è¯­ä¹‰åˆ†æ**ï¼ˆsemantic analysisï¼‰çš„å…³é”®æ¡¥æ¢ ([æ·±å…¥è§£æSyntaxNetï¼šè‡ªç„¶è¯­è¨€ç†è§£çš„åˆ©å™¨-æ˜“æºAIèµ„è®¯ | ä¸‡ç»´æ˜“æº](https://www.showapi.com/news/article/66f80f104ddd79f11a397dd7#:~:text=%E9%99%85%E5%BA%94%E7%94%A8%E3%80%82%20,1%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E6%98%AF%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E4%B8%80%EF%BC%8C%E5%AE%83%E8%B4%9F%E8%B4%A3%E5%B0%86%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E6%88%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8F%AF%E4%BB%A5%E7%90%86%E8%A7%A3%E5%92%8C%E6%93%8D%E4%BD%9C%E7%9A%84%E5%BD%A2%E5%BC%8F%E3%80%82%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E9%80%9A%E8%BF%87%E5%AF%B9))ã€‚è®¸å¤šä¸‹æ¸¸åº”ç”¨éƒ½ä¾èµ–å¥æ³•åˆ†æçš„ç»“æœæ¥æå‡æ€§èƒ½ï¼Œå¦‚æœºå™¨ç¿»è¯‘ã€ä¿¡æ¯æ£€ç´¢å’Œé—®ç­”ç³»ç»Ÿç­‰ ([æ·±å…¥è§£æSyntaxNetï¼šè‡ªç„¶è¯­è¨€ç†è§£çš„åˆ©å™¨-æ˜“æºAIèµ„è®¯ | ä¸‡ç»´æ˜“æº](https://www.showapi.com/news/article/66f80f104ddd79f11a397dd7#:~:text=%E9%99%85%E5%BA%94%E7%94%A8%E3%80%82%20,1%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E6%98%AF%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E4%B8%80%EF%BC%8C%E5%AE%83%E8%B4%9F%E8%B4%A3%E5%B0%86%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E6%88%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8F%AF%E4%BB%A5%E7%90%86%E8%A7%A3%E5%92%8C%E6%93%8D%E4%BD%9C%E7%9A%84%E5%BD%A2%E5%BC%8F%E3%80%82%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E9%80%9A%E8%BF%87%E5%AF%B9))ã€‚æ²¡æœ‰å‡†ç¡®çš„æˆåˆ†å¥æ³•æ ‘ï¼Œæœºå™¨å°±éš¾ä»¥å‡†ç¡®æŠŠæ¡å¥å­çš„æ·±å±‚å«ä¹‰å¹¶è¿›è¡Œæ°å½“çš„å¤„ç†ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆåˆ†å¥æ³•åˆ†ææ˜¯å¥æ³•åˆ†æçš„ä¸€ç§ä¸»è¦èŒƒå¼ï¼ˆå¦ä¸€ç§æ˜¯**ä¾å­˜å¥æ³•åˆ†æ**ï¼Œdependency parsingï¼‰ã€‚æˆåˆ†å¥æ³•å¼ºè°ƒçŸ­è¯­çš„å±‚æ¬¡ç»“æ„ï¼Œè¾“å‡ºä¸€æ£µçŸ­è¯­ç»“æ„æ ‘ï¼›è€Œä¾å­˜å¥æ³•åˆ†æåˆ™å¼ºè°ƒè¯ä¸è¯çš„ä¾å­˜å…³ç³»ï¼Œè¾“å‡ºä¾å­˜å…³ç³»æ ‘ã€‚åœ¨æˆåˆ†æ ‘ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨å¥å­çš„ä¸€ä¸ªæˆåˆ†æˆ–çŸ­è¯­ï¼›åœ¨ä¾å­˜æ ‘ä¸­ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨å¥å­ä¸­çš„è¯ã€‚ä¸¤ç§åˆ†ææ–¹æ³•å¯ä»¥äº’ç›¸è½¬æ¢ï¼Œä¸€æ£µçŸ­è¯­ç»“æ„æ ‘å¯ä»¥å”¯ä¸€åœ°è½¬æ¢ä¸ºä¾å­˜æ ‘ï¼Œä½†ä¸€æ£µä¾å­˜å…³ç³»æ ‘å¯èƒ½å¯¹åº”å¤šç§çŸ­è¯­ç»“æ„æ ‘ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E7%9F%AD%E8%AF%AD%E7%BB%93%E6%9E%84%E5%92%8C%E4%BE%9D%E5%AD%98%E7%BB%93%E6%9E%84%E5%85%B3%E7%B3%BB))ã€‚æœ¬ç¯‡ä¸»è¦èšç„¦æˆåˆ†å¥æ³•åˆ†æåŠå…¶ç›¸å…³ç†è®ºå’Œæ–¹æ³•ã€‚

## æˆåˆ†å¥æ³•åŸºç¡€æ¦‚å¿µ

ä¸ºäº†æ·±å…¥ç†è§£æˆåˆ†å¥æ³•åˆ†æï¼Œéœ€è¦æŒæ¡ä¸€äº›åŸºç¡€æ¦‚å¿µï¼š

- **çŸ­è¯­ç»“æ„æ–‡æ³•ï¼ˆPhrase Structure Grammarï¼‰**ï¼šä¸€ç§æè¿°å¥å­ç»“æ„çš„æ–‡æ³•å½¢å¼ï¼Œå¼ºè°ƒå¥å­çš„çŸ­è¯­å±‚æ¬¡ç»“æ„ ([ç‰‡è¯­ç»“æ„è§„åˆ™ - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦](https://zh.wikipedia.org/zh-hans/%E7%89%87%E8%AA%9E%E7%B5%90%E6%A7%8B%E8%A6%8F%E5%89%87#:~:text=%E7%9F%AD%E8%AF%AD%E7%BB%93%E6%9E%84%E8%A7%84%E5%88%99%E3%80%81%E8%AF%8D%E7%BB%84%E7%BB%93%E6%9E%84%E5%BE%8B%EF%BC%8C%E6%98%AF%E4%B8%80%E7%A7%8D%E7%94%A8%E4%BA%8E%E6%8F%8F%E8%BF%B0%E7%89%B9%E5%AE%9A%E8%AF%AD%E8%A8%80%E5%8F%A5%E6%B3%95%E7%9A%84%E9%87%8D%E5%86%99%E8%A7%84%E5%88%99%EF%BC%8C%E4%B8%8E%E8%AF%BA%E5%A7%86%C2%B7%E4%B9%94%E5%A7%86%E6%96%AF%E5%9F%BA%E5%9C%A81957%E5%B9%B4,categories%EF%BC%8C%E8%AF%8D%E7%B1%BB%EF%BC%89%E5%92%8C%E7%89%87%E8%AF%AD%E8%8C%83%E7%95%B4%EF%BC%88phrasal%20categories%EF%BC%89%E3%80%82%E5%B8%B8%E7%94%A8%E7%9A%84%E7%89%87%E8%AF%AD%E7%BB%93%E6%9E%84%E8%A7%84%E5%88%99%E6%98%AF%E6%A0%B9%E6%8D%AE%E6%88%90%E5%88%86%E5%85%B3%E7%B3%BB%EF%BC%88constituency))ã€‚çŸ­è¯­ç»“æ„æ–‡æ³•ä½¿ç”¨**çŸ­è¯­ç»“æ„è§„åˆ™**ï¼ˆphrase structure rulesï¼‰å°†å¥å­é€çº§åˆ†è§£ä¸ºå…¶ç»„æˆéƒ¨åˆ† ([ç‰‡è¯­ç»“æ„è§„åˆ™ - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦](https://zh.wikipedia.org/zh-hans/%E7%89%87%E8%AA%9E%E7%B5%90%E6%A7%8B%E8%A6%8F%E5%89%87#:~:text=%E7%9F%AD%E8%AF%AD%E7%BB%93%E6%9E%84%E8%A7%84%E5%88%99%E3%80%81%E8%AF%8D%E7%BB%84%E7%BB%93%E6%9E%84%E5%BE%8B%EF%BC%8C%E6%98%AF%E4%B8%80%E7%A7%8D%E7%94%A8%E4%BA%8E%E6%8F%8F%E8%BF%B0%E7%89%B9%E5%AE%9A%E8%AF%AD%E8%A8%80%E5%8F%A5%E6%B3%95%E7%9A%84%E9%87%8D%E5%86%99%E8%A7%84%E5%88%99%EF%BC%8C%E4%B8%8E%E8%AF%BA%E5%A7%86%C2%B7%E4%B9%94%E5%A7%86%E6%96%AF%E5%9F%BA%E5%9C%A81957%E5%B9%B4,categories%EF%BC%8C%E8%AF%8D%E7%B1%BB%EF%BC%89%E5%92%8C%E7%89%87%E8%AF%AD%E8%8C%83%E7%95%B4%EF%BC%88phrasal%20categories%EF%BC%89%E3%80%82%E5%B8%B8%E7%94%A8%E7%9A%84%E7%89%87%E8%AF%AD%E7%BB%93%E6%9E%84%E8%A7%84%E5%88%99%E6%98%AF%E6%A0%B9%E6%8D%AE%E6%88%90%E5%88%86%E5%85%B3%E7%B3%BB%EF%BC%88constituency))ã€‚è¿™äº›ç»„æˆéƒ¨åˆ†ç§°ä¸º**å¥æ³•èŒƒç•´**ï¼ˆsyntactic categoriesï¼‰ï¼ŒåŒ…æ‹¬**è¯æ±‡èŒƒç•´**ï¼ˆlexical categoriesï¼Œå¦‚åè¯ã€åŠ¨è¯ç­‰ï¼‰å’Œ**çŸ­è¯­èŒƒç•´**ï¼ˆphrasal categoriesï¼Œå¦‚åè¯çŸ­è¯­ã€åŠ¨è¯çŸ­è¯­ç­‰ï¼‰ ([ç‰‡è¯­ç»“æ„è§„åˆ™ - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦](https://zh.wikipedia.org/zh-hans/%E7%89%87%E8%AA%9E%E7%B5%90%E6%A7%8B%E8%A6%8F%E5%89%87#:~:text=%E7%9F%AD%E8%AF%AD%E7%BB%93%E6%9E%84%E8%A7%84%E5%88%99%E3%80%81%E8%AF%8D%E7%BB%84%E7%BB%93%E6%9E%84%E5%BE%8B%EF%BC%8C%E6%98%AF%E4%B8%80%E7%A7%8D%E7%94%A8%E4%BA%8E%E6%8F%8F%E8%BF%B0%E7%89%B9%E5%AE%9A%E8%AF%AD%E8%A8%80%E5%8F%A5%E6%B3%95%E7%9A%84%E9%87%8D%E5%86%99%E8%A7%84%E5%88%99%EF%BC%8C%E4%B8%8E%E8%AF%BA%E5%A7%86%C2%B7%E4%B9%94%E5%A7%86%E6%96%AF%E5%9F%BA%E5%9C%A81957%E5%B9%B4,categories%EF%BC%8C%E8%AF%8D%E7%B1%BB%EF%BC%89%E5%92%8C%E7%89%87%E8%AF%AD%E8%8C%83%E7%95%B4%EF%BC%88phrasal%20categories%EF%BC%89%E3%80%82%E5%B8%B8%E7%94%A8%E7%9A%84%E7%89%87%E8%AF%AD%E7%BB%93%E6%9E%84%E8%A7%84%E5%88%99%E6%98%AF%E6%A0%B9%E6%8D%AE%E6%88%90%E5%88%86%E5%85%B3%E7%B3%BB%EF%BC%88constituency))ã€‚çŸ­è¯­ç»“æ„æ–‡æ³•ä¸è¯ºå§†Â·ä¹”å§†æ–¯åŸºåœ¨20ä¸–çºª50å¹´ä»£æå‡ºçš„ç”Ÿæˆè¯­æ³•ç†è®ºå¯†åˆ‡ç›¸å…³ï¼Œæä¾›äº†å½¢å¼åŒ–çš„è§„åˆ™æ¥åˆ»ç”»è¯­è¨€çš„å±‚æ¬¡ç»“æ„ã€‚
    
- **å¥æ³•æ ‘ï¼ˆSyntax Tree / Parse Treeï¼‰**ï¼šå¥æ³•æ ‘æ˜¯ä¸€ç§æ ‘å½¢çš„å±‚æ¬¡ç»“æ„ï¼Œç”¨äºè¡¨ç¤ºå¥å­çš„è¯­æ³•ç»“æ„ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%E6%98%AF%E6%8C%87%E5%AF%B9%E8%BE%93%E5%85%A5%E7%9A%84%E5%8D%95%E8%AF%8D%E5%BA%8F%E5%88%97%EF%BC%88%E4%B8%80%E8%88%AC%E4%B8%BA%E5%8F%A5%E5%AD%90%EF%BC%89%E5%88%A4%E6%96%AD%E5%85%B6%E6%9E%84%E6%88%90%E6%98%AF%E5%90%A6%E5%90%88%E4%B9%8E%E7%BB%99%E5%AE%9A%E7%9A%84%E8%AF%AD%E6%B3%95%EF%BC%8C%E5%88%86%E6%9E%90%E5%87%BA%E5%90%88%E4%B9%8E%E8%AF%AD%E6%B3%95%E7%9A%84%E5%8F%A5%E5%AD%90%E7%9A%84%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E3%80%82))ã€‚åœ¨æˆåˆ†å¥æ³•åˆ†æäº§ç”Ÿçš„çŸ­è¯­ç»“æ„æ ‘ä¸­ï¼Œå†…éƒ¨èŠ‚ç‚¹ï¼ˆéç»ˆç»“ç¬¦ï¼‰æ ‡è®°ä¸ºè¯­æ³•ç±»åˆ«ï¼Œè¡¨ç¤ºä¸€ä¸ªçŸ­è¯­æˆåˆ†ï¼›å¶èŠ‚ç‚¹ï¼ˆç»ˆç»“ç¬¦ï¼‰å¯¹åº”å¥å­çš„å®é™…å•è¯ ([Parse tree - Wikipedia](https://en.wikipedia.org/wiki/Parse_tree#:~:text=The%20constituency,sentence%20John%20hit%20the%20ball))ã€‚ä¾‹å¦‚ï¼Œå¥å­â€œThe cat sits on the mat.â€çš„æˆåˆ†å¥æ³•æ ‘ä¸­ï¼Œ`S`ï¼ˆå¥å­ï¼‰æ˜¯æ ¹èŠ‚ç‚¹ï¼Œå…¶å­èŠ‚ç‚¹å¯èƒ½æ˜¯`NP`ï¼ˆåè¯çŸ­è¯­ï¼‰å’Œ`VP`ï¼ˆåŠ¨è¯çŸ­è¯­)ï¼›`NP`ä¸‹æœ‰é™å®šè¯å’Œåè¯ï¼ˆå¦‚`Det`â†’â€œtheâ€, `N`â†’â€œcatâ€ï¼‰ï¼Œ`VP`ä¸‹æœ‰åŠ¨è¯å’Œä»‹è¯çŸ­è¯­ç­‰ã€‚é€šè¿‡å¥æ³•æ ‘å¯ä»¥æ¸…æ™°åœ°çœ‹å‡ºå¥å­çš„ç»„æˆæˆåˆ†åŠå…¶å±‚æ¬¡å…³ç³»ã€‚
    
- **ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•ï¼ˆContext-Free Grammar, CFGï¼‰**ï¼šä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•æ˜¯æˆåˆ†å¥æ³•åˆ†æä¸­æœ€å¸¸ç”¨çš„å½¢å¼æ–‡æ³•ä¹‹ä¸€ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E4%B8%80%E8%88%AC%E6%9E%84%E9%80%A0%E4%B8%80%E4%B8%AA%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E9%9C%80%E8%A6%81%E8%80%83%E8%99%91%E4%BA%8C%E9%83%A8%E5%88%86%EF%BC%9A%E8%AF%AD%E6%B3%95%E7%9A%84%E5%BD%A2%E5%BC%8F%E5%8C%96%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AF%8D%E6%9D%A1%E4%BF%A1%E6%81%AF%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E5%88%86%E6%9E%90%E7%AE%97%E6%B3%95%E7%9A%84%E8%AE%BE%E8%AE%A1%E3%80%82%E7%9B%AE%E5%89%8D%E5%9C%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%AD%E5%B9%BF%E6%B3%9B%E4%BD%BF%E7%94%A8%E7%9A%84%E6%98%AF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%EF%BC%88CFG%EF%BC%89%E5%92%8C%E5%9F%BA%E4%BA%8E%E7%BA%A6%E6%9D%9F%E7%9A%84%E6%96%87%20%E6%B3%95%EF%BC%88%E5%8F%88%E7%A7%B0%E5%90%88%E4%B8%80%E8%AF%AD%E6%B3%95%EF%BC%89%E3%80%82))ã€‚å½¢å¼ä¸Šï¼ŒCFGé€šå¸¸è¡¨ç¤ºä¸ºä¸€ä¸ªå››å…ƒç»„ $G=(N,\Sigma,R,S)$ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%E6%98%AF%E4%B8%80%E4%B8%AA4%E5%85%83%E7%BB%84%24G%3D%28N%2C))ï¼šå…¶ä¸­$N$æ˜¯éç»ˆç»“ç¬¦é›†åˆï¼Œ$\Sigma$æ˜¯ç»ˆç»“ç¬¦é›†åˆï¼ˆè¯æ±‡è¡¨ï¼‰ï¼Œ$R$æ˜¯äº§ç”Ÿå¼è§„åˆ™ï¼ˆrewrite rulesï¼‰çš„æœ‰é™é›†åˆï¼Œ$S$æ˜¯å¼€å§‹ç¬¦å·(start symbol) ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%E6%98%AF%E4%B8%80%E4%B8%AA4%E5%85%83%E7%BB%84%24G%3D%28N%2C))ã€‚**äº§ç”Ÿå¼è§„åˆ™**çš„å½¢å¼ä¸º $X \rightarrow Y_1 Y_2 \dots Y_n$ï¼Œè¡¨ç¤ºéç»ˆç»“ç¬¦$X$å¯ä»¥é‡å†™ä¸ºç¬¦å·åºåˆ—$Y_1 \dots Y_n$ï¼Œå…¶ä¸­æ¯ä¸ª$Y_i$å¯ä»¥æ˜¯éç»ˆç»“ç¬¦æˆ–ç»ˆç»“ç¬¦ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=,%24S%20%5Cin%20N%24%E6%98%AF%E4%B8%80%E4%B8%AA%E7%89%B9%E6%AE%8A%E7%9A%84%E5%BC%80%E5%A7%8B%E7%AC%A6%E5%8F%B7))ã€‚ä¾‹å¦‚ï¼Œå…¸å‹çš„CFGè§„åˆ™æœ‰$S \rightarrow NP\ VP$ï¼ˆå¥å­å¯ä»¥ç”±åè¯çŸ­è¯­åŠ åŠ¨è¯çŸ­è¯­æ„æˆï¼‰ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%5C%5B%5Cbegin,split))ã€‚ä¸Šä¸‹æ–‡æ— å…³çš„å«ä¹‰æ˜¯ï¼šæ— è®ºéç»ˆç»“ç¬¦$X$å‘¨å›´çš„ä¸Šä¸‹æ–‡æ˜¯ä»€ä¹ˆï¼Œåªè¦æœ‰è§„åˆ™$X \rightarrow \alpha$ï¼Œå°±å¯ä»¥å°†$X$æ›¿æ¢ä¸º$\alpha$ ([ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³• - ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦](https://zh.wikipedia.org/zh-hans/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95#:~:text=%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%EF%BC%88%E8%8B%B1%E8%AF%AD%EF%BC%9Acontext,%E6%80%BB%E5%8F%AF%E4%BB%A5%E8%A2%AB%E5%AD%97%E4%B8%B2%20%CE%B1%20%E8%87%AA%E7%94%B1%E6%9B%BF%E6%8D%A2%EF%BC%8C%E8%80%8C%E6%97%A0%E9%9C%80%E8%80%83%E8%99%91%E5%AD%97%E7%AC%A6%20A%20%E5%87%BA%E7%8E%B0%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E3%80%82%E5%A6%82%E6%9E%9C%E4%B8%80%E4%B8%AA%E5%BD%A2%E5%BC%8F%E8%AF%AD%E8%A8%80%E6%98%AF%E7%94%B1%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%E7%94%9F%E6%88%90%E7%9A%84%EF%BC%8C%E9%82%A3%E4%B9%88%E5%8F%AF%E4%BB%A5%E8%AF%B4%E8%BF%99%E4%B8%AA%E5%BD%A2%E5%BC%8F%E8%AF%AD%E8%A8%80%E6%98%AF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E7%9A%84%E3%80%82%EF%BC%88%E6%9D%A1%E7%9B%AE%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E8%AF%AD%E8%A8%80%EF%BC%89%E3%80%82))ã€‚è¿™æ„å‘³ç€è§„åˆ™åº”ç”¨ä¸å—å‰åæ–‡é™åˆ¶ã€‚CFGèƒ½å¤Ÿåˆ»ç”»å¤§éƒ¨åˆ†è‡ªç„¶è¯­è¨€çš„çŸ­è¯­ç»“æ„ï¼Œæ˜¯è§£æå¥æ³•æ ‘çš„åŸºç¡€æ–‡æ³•æ¨¡å‹ã€‚
    

ä»¥ä¸Šæ¦‚å¿µå…±åŒæ„æˆäº†æˆåˆ†å¥æ³•åˆ†æçš„ç†è®ºåŸºç¡€ï¼šçŸ­è¯­ç»“æ„æ–‡æ³•æä¾›äº†æˆ‘ä»¬åˆ’åˆ†å¥å­æˆåˆ†çš„æ€æƒ³ï¼ŒCFGç»™å‡ºäº†ä¸¥æ ¼çš„å½¢å¼åŒ–å®šä¹‰å’Œè§„åˆ™é›†åˆï¼Œè€Œå¥æ³•æ ‘åˆ™æ˜¯æœ€ç»ˆåˆ†æè¾“å‡ºçš„ç»“æ„åŒ–è¡¨ç¤ºã€‚ç†è§£è¿™äº›æ¦‚å¿µæœ‰åŠ©äºè¿›ä¸€æ­¥æŠŠæ¡æˆåˆ†å¥æ³•åˆ†æçš„æ–¹æ³•å’Œç®—æ³•ã€‚

## æˆåˆ†å¥æ³•åˆ†æçš„å½¢å¼åŒ–æè¿°

ä»å½¢å¼è¯­è¨€ç†è®ºçš„è§’åº¦ï¼Œå¯ä»¥æ›´ä¸¥æ ¼åœ°æè¿°æˆåˆ†å¥æ³•åˆ†æè¿‡ç¨‹ã€‚é¦–å…ˆï¼Œå¦‚ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬é€šå¸¸ç”¨ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•(CFG)æ¥åˆ»ç”»å¥å­çš„è¯­æ³•è§„åˆ™ä½“ç³» ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E4%B8%80%E8%88%AC%E6%9E%84%E9%80%A0%E4%B8%80%E4%B8%AA%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E9%9C%80%E8%A6%81%E8%80%83%E8%99%91%E4%BA%8C%E9%83%A8%E5%88%86%EF%BC%9A%E8%AF%AD%E6%B3%95%E7%9A%84%E5%BD%A2%E5%BC%8F%E5%8C%96%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AF%8D%E6%9D%A1%E4%BF%A1%E6%81%AF%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98%EF%BC%8C%E5%88%86%E6%9E%90%E7%AE%97%E6%B3%95%E7%9A%84%E8%AE%BE%E8%AE%A1%E3%80%82%E7%9B%AE%E5%89%8D%E5%9C%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%AD%E5%B9%BF%E6%B3%9B%E4%BD%BF%E7%94%A8%E7%9A%84%E6%98%AF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%EF%BC%88CFG%EF%BC%89%E5%92%8C%E5%9F%BA%E4%BA%8E%E7%BA%A6%E6%9D%9F%E7%9A%84%E6%96%87%20%E6%B3%95%EF%BC%88%E5%8F%88%E7%A7%B0%E5%90%88%E4%B8%80%E8%AF%AD%E6%B3%95%EF%BC%89%E3%80%82))ã€‚ä¸€ä¸ªCFG $G=(N,\Sigma,R,S)$å®šä¹‰äº†ä¸€ç§è¯­è¨€ï¼Œå³æ‰€æœ‰èƒ½ä»å¼€å§‹ç¬¦å·$S$å‡ºå‘ï¼Œé€šè¿‡ä¸€ç³»åˆ—äº§ç”Ÿå¼æ¨å¯¼å‡ºç»ˆç»“ç¬¦ä¸²çš„é›†åˆã€‚ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%E6%98%AF%E4%B8%80%E4%B8%AA4%E5%85%83%E7%BB%84%24G%3D%28N%2C))ç»™å‡ºäº†CFGçš„å½¢å¼å®šä¹‰ï¼Œå…¶ä¸­æ¯æ¡äº§ç”Ÿå¼è§„åˆ™å½¢å¦‚ $A \to \beta$ï¼ˆ$A\in N$, $\beta \in (N \cup \Sigma)^*$ï¼‰ã€‚è¿™äº›è§„åˆ™æç»˜äº†å¦‚ä½•å°†é«˜å±‚çš„å¥æ³•æˆåˆ†é€æ­¥ç»†åˆ†ä¸ºæ›´ä½å±‚çš„æˆåˆ†æˆ–å…·ä½“è¯è¯­ã€‚

**æ¨å¯¼ï¼ˆDerivationï¼‰*_æ˜¯æŒ‡æŒ‰ç…§æ–‡æ³•è§„åˆ™å°†å¼€å§‹ç¬¦å·é€æ­¥æ›¿æ¢ä¸ºç»ˆç»“ç¬¦åºåˆ—çš„è¿‡ç¨‹ã€‚å¦‚æœå­˜åœ¨ä¸€ç³»åˆ—è§„åˆ™åº”ç”¨ä½¿å¾—$S \Rightarrow w$ï¼ˆè¯»ä½œâ€œ$S$æ¨å¯¼å‡º$w$â€ï¼‰ï¼Œå…¶ä¸­$w$æ˜¯ä»…ç”±ç»ˆç»“ç¬¦æ„æˆçš„ä¸²ï¼Œé‚£ä¹ˆ$w$å³å±äºè¯¥æ–‡æ³•ç”Ÿæˆçš„è¯­è¨€ã€‚æ¨å¯¼å¯ä»¥è§†ä¸ºè§£æçš„è¿‡ç¨‹ï¼Œä¾‹å¦‚ç»™å®šå¦‚ä¸‹ç®€å•æ–‡æ³•è§„åˆ™ï¼š

Sâ†’NPÂ VPNPâ†’DTÂ NNVPâ†’ViDTâ†’theNNâ†’manViâ†’sleepsS \rightarrow NP\ VP \\ NP \rightarrow DT\ NN \\ VP \rightarrow Vi \\ DT \rightarrow \text{the} \\ NN \rightarrow \text{man} \\ Vi \rightarrow \text{sleeps}

ä»å¼€å§‹ç¬¦å·$S$å‡ºå‘ï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œä¸€ç³»åˆ—æ¨å¯¼ï¼š

Sâ‡’NPÂ VPâ‡’DTÂ NNÂ VPâ‡’theÂ NNÂ VPâ‡’theÂ manÂ VPâ‡’theÂ manÂ Viâ‡’theÂ manÂ sleepsâ€‰.S \Rightarrow NP\ VP \Rightarrow DT\ NN\ VP \Rightarrow \text{the}\ NN\ VP \Rightarrow \text{the}\ \text{man}\ VP \Rightarrow \text{the}\ \text{man}\ Vi \Rightarrow \text{the}\ \text{man}\ \text{sleeps}\,.

ä¸Šè¿°æ¨å¯¼åºåˆ—å±•ç¤ºäº†å¦‚ä½•ä»å¥å­æˆåˆ†é€æ­¥å±•å¼€ç›´åˆ°å¾—åˆ°ç»ˆç»“ç¬¦ä¸²â€œthe man sleepsâ€ã€‚æ¯ä¸€æ­¥æ›¿æ¢åº”ç”¨çš„äº§ç”Ÿå¼è§„åˆ™å¦‚æ‹¬å·æ‰€ç¤ºã€‚æ•´ä¸ªæ¨å¯¼è¿‡ç¨‹å®é™…ä¸Šå¯¹åº”äºä¸€æ£µ**å¥æ³•æ ‘**ï¼šæ ¹èŠ‚ç‚¹ä¸º$S$ï¼Œå±•å¼€ä¸º`NP`å’Œ`VP`å­èŠ‚ç‚¹ï¼›`NP`è¿›ä¸€æ­¥å±•å¼€ä¸º`DT`å’Œ`NN`å¶å­èŠ‚ç‚¹â€œtheâ€å’Œâ€œmanâ€ï¼›`VP`å±•å¼€ä¸º`Vi`å¶å­èŠ‚ç‚¹â€œsleepsâ€ã€‚æ¢è¨€ä¹‹ï¼Œ**å¥æ³•æ ‘ä¸æ¨å¯¼æ˜¯ç­‰ä»·çš„**â€”â€”æ¨å¯¼è¿‡ç¨‹ä¸­çš„æ¯ä¸€æ¬¡è§„åˆ™æ›¿æ¢åœ¨æ ‘ä¸­å½¢æˆä¸€ä¸ªçˆ¶èŠ‚ç‚¹ä¸ä¸€ç»„å­èŠ‚ç‚¹çš„å…³ç³»ã€‚é€šè¿‡è¿™æ ·çš„å¥æ³•æ ‘ç»“æ„ï¼Œæˆ‘ä»¬æ˜ç¡®äº†å¥å­çš„å±‚æ¬¡ç»„åˆæ–¹å¼ã€‚

å½¢å¼åŒ–åœ°ï¼Œä¸€ä¸ªå¥å­çš„å¥æ³•æ ‘æ»¡è¶³ä»¥ä¸‹æ€§è´¨ï¼šæ ¹èŠ‚ç‚¹æ˜¯å¼€å§‹ç¬¦å·$S$ï¼›æ¯ä¸€ä¸ªå†…éƒ¨èŠ‚ç‚¹å¯¹åº”æ–‡æ³•$R$ä¸­çš„æŸæ¡äº§ç”Ÿå¼è§„åˆ™ï¼Œå­©å­èŠ‚ç‚¹åºåˆ—å°±æ˜¯è¯¥è§„åˆ™å³ä¾§çš„ç¬¦å·åºåˆ—ï¼›å¶èŠ‚ç‚¹è‡ªå·¦å‘å³è¿æ¥èµ·æ¥æ°å¥½æ„æˆåŸå¥ï¼ˆç»ˆç»“ç¬¦ä¸²ï¼‰ã€‚å¦‚æœä¸€ä¸ªå¥å­æœ‰è‡³å°‘ä¸€æ£µæ»¡è¶³ä¸Šè¿°æ¡ä»¶çš„å¥æ³•æ ‘ï¼Œé‚£ä¹ˆè¯¥å¥æŒ‰ç…§æ–‡æ³•æ˜¯**è¯­æ³•åˆæ³•**çš„ï¼ˆgrammaticalï¼‰ï¼›åä¹‹è‹¥æ²¡æœ‰ä»»ä½•æœ‰æ•ˆæ ‘ï¼Œåˆ™å¥å­ä¸ç¬¦åˆæ–‡æ³•è§„åˆ™ã€‚æˆåˆ†å¥æ³•åˆ†æçš„é¦–è¦ä»»åŠ¡ä¹‹ä¸€å°±æ˜¯åˆ¤æ–­è¾“å…¥å¥å­æ˜¯å¦èƒ½ç”±æ–‡æ³•ç”Ÿæˆï¼Œå³åˆ¤å®šå…¶è¯­æ³•åˆæ³•æ€§ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%BB%E5%8A%A1%E4%B8%BB%E8%A6%81%E6%9C%89%E4%B8%89%E4%B8%AA%EF%BC%9A))ã€‚ä¸€æ—¦ç¡®è®¤å¥å­å±äºè¯­è¨€ï¼Œå½“å¥å­å­˜åœ¨ä¸æ­¢ä¸€ç§æ¨å¯¼æ–¹å¼ï¼ˆå³å­˜åœ¨å¤šæ£µä¸åŒçš„å¥æ³•æ ‘ï¼‰æ—¶ï¼Œå°±å‡ºç°äº†**æ­§ä¹‰**ç°è±¡ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E5%9B%A0%E4%B8%BA%E6%AD%A7%E4%B9%89%EF%BC%8C%E4%B8%80%E4%B8%AA%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8F%AF%E8%83%BD%E6%9C%89%E5%A4%9A%E7%A7%8D%E6%8E%A8%E5%AF%BC%E6%96%B9%E6%B3%95%EF%BC%8C%E6%88%91%E4%BB%AC%E6%8A%8A%E6%89%80%E6%9C%89%E8%83%BD%E5%A4%9F%E6%8E%A8%E5%AF%BC%E5%AD%97%E7%AC%A6%E4%B8%B2s%E7%9A%84%E6%8E%A8%E5%AF%BC%E6%96%B9%E6%B3%95%E9%9B%86%E5%90%88%E8%AE%B0%E4%B8%BA%24%5Cmathcal))ã€‚å¤„ç†æ­§ä¹‰å’Œé€‰å‡ºæœ€åˆç†çš„å¥æ³•æ ‘æ˜¯å¥æ³•åˆ†æå™¨çš„å¦ä¸€é‡è¦ä»»åŠ¡ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=1))ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä»‹ç»å®ç°æˆåˆ†å¥æ³•åˆ†æçš„è‹¥å¹²å…¸å‹ç®—æ³•ï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•é«˜æ•ˆåœ°æ„å»ºå¥æ³•æ ‘ã€‚

## å¸¸ç”¨ç®—æ³•

é’ˆå¯¹ç»™å®šçš„æ–‡æ³•å’Œå¥å­ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°æ„å»ºå¥æ³•æ ‘æ˜¯æˆåˆ†å¥æ³•åˆ†æçš„æ ¸å¿ƒé—®é¢˜ã€‚ç†è®ºä¸Šï¼Œå¯ä»¥é€šè¿‡ä¸åŒç­–ç•¥éå†æˆ–è®¡ç®—å¯èƒ½çš„æ¨å¯¼ã€‚ä¸‹é¢ä»‹ç»å‡ ç§å¸¸ç”¨çš„è§£æç®—æ³•ï¼šCKYç®—æ³•ã€ç©·ä¸¾æœç´¢å’Œé€’å½’ä¸‹é™è§£æï¼Œå®ƒä»¬ä»£è¡¨äº†åŠ¨æ€è§„åˆ’ã€æš´åŠ›æœç´¢å’Œé€’å½’ä¸‹é™ä¸‰ç§ä¸åŒçš„æ€è·¯ã€‚

### CKYç®—æ³•

**CKYç®—æ³•**ï¼ˆCockeâ€“Kasamiâ€“Younger algorithmï¼‰æ˜¯ä¸€ç§ç»å…¸çš„åŸºäºåŠ¨æ€è§„åˆ’çš„ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•è§£æç®—æ³•ã€‚CKYç®—æ³•è¦æ±‚è¾“å…¥æ–‡æ³•é¦–å…ˆè½¬æ¢ä¸º**ä¹”å§†æ–¯åŸºèŒƒå¼**ï¼ˆChomsky Normal Form, CNFï¼‰ï¼Œå³æ¯æ¡äº§ç”Ÿå¼è¦ä¹ˆå½¢å¦‚$A \to B\ C$ï¼ˆä¸¤ä¸ªéç»ˆç»“ç¬¦ï¼‰è¦ä¹ˆå½¢å¦‚$A \to a$ï¼ˆä¸€ä¸ªç»ˆç»“ç¬¦ï¼‰ï¼Œæˆ–æ˜¯ç©ºä¸²è§„åˆ™$S \to \epsilon$ ([What is the CYK algorithm?](https://how.dev/answers/what-is-the-cyk-algorithm#:~:text=In%20a%20CYK%20algorithm%2C%20the,be%20in%20Chomsky%20normal%20form))ã€‚ä»»ä½•ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•éƒ½å¯ä»¥ç­‰ä»·åœ°è½¬æ¢ä¸ºCNFè€Œä¸æ”¹å˜å…¶ç”Ÿæˆè¯­è¨€ ([æˆåˆ†åˆ†æï¼ˆConstituency Parsingï¼‰ - çŸ¥ä¹ä¸“æ ](https://zhuanlan.zhihu.com/p/404821921#:~:text=%E5%AF%B9%E4%BA%8E%E4%B8%80%E4%B8%AA%E4%BB%BB%E6%84%8F%E7%BB%99%E5%AE%9A%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95%EF%BC%8C%E9%83%BD%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8CKY%20%E7%AE%97%E6%B3%95%EF%BC%88Cocke))ã€‚åœ¨æ–‡æ³•æ ‡å‡†åŒ–åï¼ŒCKYç®—æ³•é€šè¿‡å¡«å……**è¡¨æ ¼ï¼ˆchartï¼‰**æ¥è§£æå¥å­ï¼šå®ƒæ„å»ºä¸€ä¸ªä¸‰è§’å½¢åŠ¨æ€è§„åˆ’è¡¨æ ¼ï¼Œè¡¨æ ¼çš„$i,j$å•å…ƒï¼ˆå¯¹åº”å¥å­ä¸­ä»ä½ç½®$i$åˆ°$j$çš„å­ä¸²ï¼‰ç”¨äºè®°å½•èƒ½ç”Ÿæˆè¯¥å­ä¸²çš„éç»ˆç»“ç¬¦é›†åˆ ([What is the CYK algorithm?](https://how.dev/answers/what-is-the-cyk-algorithm#:~:text=In%20the%20CYK%20algorithm%2C)) ([What is the CYK algorithm?](https://how.dev/answers/what-is-the-cyk-algorithm#:~:text=,%E2%80%98w%E2%80%99%20or%20the%20whole%20string))ã€‚ç®—æ³•å¤§è‡´æµç¨‹ä¸ºï¼š

1. **åˆå§‹åŒ–**ï¼šå¯¹å¥å­æ¯ä¸ªè¯$i$ï¼ŒæŸ¥æ‰¾æ‰€æœ‰èƒ½ç›´æ¥äº§ç”Ÿè¯¥è¯çš„éç»ˆç»“ç¬¦$X$ï¼ˆå³è§„åˆ™$X \to word_i$ï¼‰ï¼Œå°†$X$è®°å½•åœ¨è¡¨æ ¼å•å…ƒ$(i,i)$ä¸­ ([What is the CYK algorithm?](https://how.dev/answers/what-is-the-cyk-algorithm#:~:text=,%E2%80%98w%E2%80%99%20or%20the%20whole%20string))ã€‚
    
2. **é€’å½’å¡«è¡¨**ï¼šæŒ‰å­ä¸²é•¿åº¦ç”±å°åˆ°å¤§é€’å¢ï¼Œä¾æ¬¡è®¡ç®—è·¨åº¦ä¸º2,3,...,nçš„å„å­ä¸²$(i,j)$å¯èƒ½å¯¹åº”çš„éç»ˆç»“ç¬¦ã€‚å¯¹äºæ¯ä¸ªå­ä¸²$(i,j)$ï¼Œå°è¯•æ‰€æœ‰å¯èƒ½çš„æ‹†åˆ†ä½ç½®$k$ï¼ˆä½¿å¾—å­ä¸²$(i,j)$åˆ’åˆ†ä¸ºä¸¤éƒ¨åˆ†$(i,k)$å’Œ$(k+1,j)$ï¼‰ã€‚å¦‚æœå­˜åœ¨è§„åˆ™$A \to B\ C$ï¼Œå…¶ä¸­$B$å±äºè¡¨æ ¼$(i,k)$ã€$C$å±äºè¡¨æ ¼$(k+1,j)$ï¼Œåˆ™è¯´æ˜éç»ˆç»“ç¬¦$A$å¯ä»¥ç”Ÿæˆå­ä¸²$(i,j)$ ([What is the CYK algorithm?](https://how.dev/answers/what-is-the-cyk-algorithm#:~:text=where%20w%20i%20is%20part,%E2%80%98w%E2%80%99%20or%20the%20whole%20string))ã€‚å°†$A$åŠ å…¥è¡¨æ ¼$(i,j)$çš„å€™é€‰åˆ—è¡¨ä¸­ã€‚è‹¥ä½¿ç”¨æ¦‚ç‡æ–‡æ³•(PCFG)ï¼Œåˆ™åœ¨è®¡ç®—æ—¶å¯ç´¯ç§¯æ¯ç§ç”Ÿæˆçš„æ¦‚ç‡å¹¶è®°å½•æœ€å¤§æ¦‚ç‡çš„æ„é€ æ–¹å¼ã€‚
    
3. **å®Œæˆè§£æ**ï¼šå½“å¡«è¡¨è¿‡ç¨‹è¦†ç›–æ•´ä¸ªå¥å­ï¼ˆè·¨åº¦$n$ï¼‰æ—¶ï¼Œæ£€æŸ¥è¡¨æ ¼é¡¶ç«¯å•å…ƒ$(1,n)$æ˜¯å¦åŒ…å«å¼€å§‹ç¬¦å·$S$ã€‚å¦‚æœæ˜¯ï¼Œåˆ™å¥å­å±äºè¯¥æ–‡æ³•å¹¶å¯ç”±æ­¤æå–å¥æ³•æ ‘ï¼ˆæˆ–æ¦‚ç‡æœ€å¤§çš„å¥æ³•æ ‘ï¼‰ï¼›è‹¥å¦ï¼Œåˆ™å¥å­ä¸ç¬¦åˆæ–‡æ³•ï¼Œæ— æ³•è§£æå‡ºæ ‘ã€‚
    

CKYç®—æ³•åˆ©ç”¨äº†åŠ¨æ€è§„åˆ’é¿å…é‡å¤è®¡ç®—å­é—®é¢˜ï¼Œå¤§å¤§æé«˜äº†è§£ææ•ˆç‡ã€‚å…¶æ—¶é—´å¤æ‚åº¦ä¸º$O(n^3)$ï¼Œå…¶ä¸­$n$ä¸ºå¥å­é•¿åº¦ ([What is the CYK algorithm?](https://how.dev/answers/what-is-the-cyk-algorithm#:~:text=The%20running%20time%20of%20the,3))ã€‚å¯¹äºå›ºå®šæ–‡æ³•ï¼Œ$O(n^3)$å·²ç»æ˜¯ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•è§£æå·²çŸ¥çš„æœ€ä¼˜æ¸è¿›å¤æ‚åº¦ç­‰çº§ä¹‹ä¸€ï¼ˆä¸€èˆ¬è¯æ˜CFGè§£æä¸å¯èƒ½ä¼˜äº$O(n^2)$ï¼Œè€Œ$O(n^3)$ç®—æ³•å¦‚CKYæ˜¯å¯è¡Œæ–¹æ¡ˆï¼‰ ([CYK Calculator](https://cyk.rushikeshtote.com/#:~:text=CYK%20Calculator%20The%20Cocke,))ã€‚**ä¼˜ç‚¹**åœ¨äºï¼šCKYèƒ½å®Œæ•´åœ°æ¢ç´¢æ‰€æœ‰å¯èƒ½è§£æï¼Œåœ¨å¤šä¹‰æ€§å­˜åœ¨æ—¶å¯æ„å»º**è§£ææ£®æ—**ï¼ˆparse forestï¼‰å›Šæ‹¬å…¨éƒ¨å¥æ³•æ ‘ï¼Œå¹¶å¯åœ¨å…¶ä¸Šåº”ç”¨æ¦‚ç‡ç­‰ä¿¡æ¯é€‰ä¼˜ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E5%A6%82%E6%9E%9C%E4%B8%80%E4%B8%AA%E5%8F%A5%E5%AD%90%28%E5%AD%97%E7%AC%A6%E4%B8%B2%29%E6%98%AF%E6%9C%89%E6%AD%A7%E4%B9%89%E7%9A%84%EF%BC%8C%E9%82%A3%E4%B9%88%24%5Cvert%20%5Cmathcal%7BT%7D_G%28s%29%20%5Cvert%20,0%24%E3%80%82%E8%80%8CPCFG%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%E6%98%AF%E5%AF%B9%E4%BA%8EG%E7%9A%84%E6%89%80%E6%9C%89%E6%8E%A8%E5%AF%BCt%EF%BC%8C%E6%88%91%E4%BB%AC%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%EF%BC%8C%E4%BD%BF%E5%BE%97%EF%BC%9A)) ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%5C%5B%5Cunderset))ã€‚ç›¸è¾ƒäºç©·ä¸¾æœç´¢ï¼ŒåŠ¨æ€è§„åˆ’æå¤§é™ä½äº†è®¡ç®—å†—ä½™ï¼Œç¡®ä¿äº†å¤šé¡¹å¼æ—¶é—´å¯è¡Œæ€§ã€‚**ç¼ºç‚¹**åˆ™åŒ…æ‹¬ï¼šè¦æ±‚æ–‡æ³•è½¬ä¸ºCNFå¯èƒ½å¯¼è‡´è§„åˆ™æ•°é‡å¢å¤šå’Œå®ç°å¤æ‚æ€§å¢åŠ ï¼ˆä¸è¿‡è¿™ä¸€æ­¥æ˜¯æœºæ¢°çš„ï¼‰ï¼›æ­¤å¤–$O(n^3)$åœ¨$n$è¾ƒå¤§æ—¶è®¡ç®—ä»£ä»·ä»ç„¶ä¸å®¹å¿½è§†ï¼Œä¾‹å¦‚è§£æé•¿å¥å­æˆ–æ•´ä¸ªæ–‡æ¡£æ—¶é€Ÿåº¦å’Œå†…å­˜æ¶ˆè€—éƒ½æ˜¯æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼ŒCKYç®—æ³•å¸¸ä¼šç»“åˆå‰ªæç­–ç•¥ï¼ˆå¦‚è¯­æ³•è§„åˆ™çš„å…ˆéªŒæ¦‚ç‡å‰ªæï¼‰æˆ–æ”¹è¿›çš„æ•°æ®ç»“æ„æ¥æå‡æ•ˆç‡ã€‚

### ç©·ä¸¾æœç´¢

**ç©·ä¸¾æœç´¢**ï¼ˆbrute-force searchï¼‰æ˜¯ä¸€ç§æ¦‚å¿µä¸Šæœ€ç›´æ¥ä½†ä»£ä»·æé«˜çš„è§£ææ–¹æ³•ï¼Œå³ä¸ä½¿ç”¨åŠ¨æ€è§„åˆ’ä¼˜åŒ–ï¼Œç®€å•åœ°æšä¸¾è¾“å…¥å¥å­å¯èƒ½çš„æ‰€æœ‰å¥æ³•ç»“æ„ã€‚å…·ä½“æ¥è¯´ï¼Œç©·ä¸¾ç®—æ³•ä¼šå°è¯•å¥å­çš„æ‰€æœ‰å¯èƒ½åˆ‡åˆ†å’Œè§„åˆ™åº”ç”¨ç»„åˆï¼Œç”Ÿæˆæ‰€æœ‰ç¬¦åˆæ–‡æ³•çš„å¥æ³•æ ‘ã€‚è¿™ç§æ–¹æ³•å¯ä»¥è§†ä¸ºå¯¹æ¨å¯¼è¿‡ç¨‹çš„æ·±åº¦ä¼˜å…ˆæˆ–å¹¿åº¦ä¼˜å…ˆéå†â€”â€”éå†æ‰€æœ‰$S$å¯ä»¥å¯¼å‡ºçš„å¥å­ï¼Œæ‰¾å‡ºå…¶ä¸­ä¸è¾“å…¥ä¸²åŒ¹é…çš„é‚£æ£µæˆ–é‚£äº›æ ‘ã€‚

ç©·ä¸¾æœç´¢çš„**ä¼˜åŠ¿**åœ¨äºæ€æƒ³ç®€å•ã€å…¨é¢ï¼šç†è®ºä¸Šå®ƒä¸ä¼šé—æ¼ä»»ä½•ä¸€ç§å¯èƒ½çš„è§£æã€‚ç„¶è€Œï¼Œå…¶**åŠ£åŠ¿**ä¹Ÿæ˜¯æ˜¾è€Œæ˜“è§çš„ï¼Œå°±æ˜¯è®¡ç®—å¤æ‚åº¦æé«˜ã€‚å¯¹äºé•¿åº¦ä¸º$n$çš„å¥å­ï¼Œå¯èƒ½çš„å¥æ³•æ ‘æ•°é‡å¢é•¿éå¸¸å¿«ã€‚åœ¨äºŒå…ƒè§„åˆ™æƒ…å†µä¸‹ï¼Œä¸åŒçš„äºŒå‰è§£ææ ‘æ•°é‡ä¸è‘—åçš„**å¡ç‰¹å…°æ•°**ï¼ˆCatalan numberï¼‰æœ‰å…³ï¼šå¯èƒ½çš„äºŒå‰æ ‘æ•°ä¸º$C_n = \frac{1}{n+1}\binom{2n}{n}$ ([Parse tree - Wikipedia](https://en.wikipedia.org/wiki/Parse_tree#:~:text=For%20binary%20trees%20,n))ã€‚å¡ç‰¹å…°æ•°çš„å¢é•¿é€Ÿåº¦å¤§è‡´ä¸º$O(4^n / (n^{3/2}\sqrt{\pi}))$ï¼Œéšç€$n$å¢åŠ è¿…é€Ÿè¶‹è¿‘äºæŒ‡æ•°çº§ã€‚è¿™æ„å‘³ç€å³ä½¿ä¸€ä¸ªä¸­ç­‰é•¿åº¦çš„å¥å­ä¹Ÿå¯èƒ½æœ‰å¤©æ–‡æ•°é‡çš„è§£ææ ‘ï¼ˆç‰¹åˆ«æ˜¯åœ¨å­˜åœ¨å¤šé‡æ­§ä¹‰çš„æƒ…å†µä¸‹ï¼‰ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªå«æœ‰å¤šä¸ªä»‹è¯çŸ­è¯­æˆ–ä»å¥çš„å¥å­ï¼Œå…¶ä¸åŒç»„åˆä½œç”¨çš„è§£ææ ‘å¯èƒ½æˆç™¾ä¸Šåƒã€‚å®Œå…¨çš„ç©·ä¸¾æœç´¢éœ€è¦æšä¸¾å¹¶éªŒè¯æ‰€æœ‰è¿™äº›å¯èƒ½ï¼Œè®¡ç®—é‡éšå¥å­é•¿åº¦æ€¥å‰§è†¨èƒ€ï¼Œå®é™…ä¸Šæ— æ³•åœ¨åˆç†æ—¶é—´å†…å®Œæˆã€‚

ç”±äºä¸Šè¿°åŸå› ï¼Œçº¯ç²¹çš„ç©·ä¸¾æœç´¢å‡ ä¹ä»ä¸ç”¨äºå®é™…çš„æˆåˆ†å¥æ³•åˆ†æå™¨å®ç°ä¸­ã€‚å®ƒæ›´å¤šæ˜¯ä¸€ä¸ªç†è®ºä¸Šçš„ä¸Šç•Œæˆ–è€…ç”¨äºæ¼”ç¤ºçš„å°è§„æ¨¡åœºæ™¯ã€‚åœ¨å®é™…è§£æè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸é‡‡ç”¨åŠ¨æ€è§„åˆ’ç®—æ³•ï¼ˆå¦‚CKYã€Earleyç®—æ³•ç­‰ï¼‰éšå¼åœ°æ¢ç´¢æ‰€æœ‰å¯èƒ½è§£æï¼Œè€Œä¸ä¼šçœŸçš„ç”Ÿæˆæ¯æ£µæ ‘ã€‚å³ä¾¿å¦‚æ­¤ï¼Œç†è§£ç©·ä¸¾æœç´¢çš„æç«¯å¼€é”€æœ‰åŠ©äºæˆ‘ä»¬è®¤è¯†è§£æé—®é¢˜çš„éš¾åº¦ï¼Œä»¥åŠä¸ºä½•éœ€è¦æ›´èªæ˜çš„ç®—æ³•ã€‚æ€»çš„æ¥è¯´ï¼Œç©·ä¸¾æœç´¢çš„æ–¹æ³•**ä¼˜ç‚¹**ä»…åœ¨äºå®ç°ä¸Šç›´è§‚å’Œå®Œæ•´æ€§ï¼Œè€Œ**ç¼ºç‚¹**æ˜¯ä¸å¯æ¥å—çš„ä½æ•ˆç‡ï¼›åªæœ‰åœ¨å¥å­éå¸¸çŸ­æˆ–è€…ä¸ºäº†æµ‹è¯•/æšä¸¾æ‰€æœ‰è§£æçš„æƒ…å†µä¸‹ï¼Œæ‰å¯èƒ½è€ƒè™‘æš´åŠ›ç©·ä¸¾çš„æ–¹æ³•ã€‚

### é€’å½’ä¸‹é™åˆ†æ

**é€’å½’ä¸‹é™åˆ†æ**ï¼ˆRecursive Descent Parsingï¼‰æ˜¯ä¸€ç§è‡ªé¡¶å‘ä¸‹çš„è§£ææ–¹æ³•ï¼Œé€šå¸¸ä»¥é€’å½’è¿‡ç¨‹å®ç°æ¯ä¸ªéç»ˆç»“ç¬¦çš„è§£æã€‚è§£æå™¨ä¸ºæ–‡æ³•ä¸­çš„æ¯ä¸ªéç»ˆç»“ç¬¦ç¼–å†™ä¸€ä¸ªé€’å½’å‡½æ•°ï¼Œå°è¯•æŒ‰ç…§è¯¥éç»ˆç»“ç¬¦çš„äº§ç”Ÿå¼è§„åˆ™å»åŒ¹é…è¾“å…¥åºåˆ— ([Recursive descent parser - Wikipedia](https://en.wikipedia.org/wiki/Recursive_descent_parser#:~:text=In%20computer%20science%20%2C%20a,2))ã€‚ä¾‹å¦‚ï¼Œå¯¹äºéç»ˆç»“ç¬¦$S$ï¼Œå¯èƒ½æœ‰å‡½æ•°`parseS()`å°è¯•è§„åˆ™$S \to A\ B$æˆ–$S \to C$ç­‰ï¼Œæ¯ä¸ªå­éç»ˆç»“ç¬¦è°ƒç”¨å¯¹åº”çš„è§£æå‡½æ•°ï¼ŒæŒ‰éœ€è¿›è¡Œå›æº¯(backtracking)å°è¯•ä¸åŒè§„åˆ™åˆ†æ”¯ã€‚

é€’å½’ä¸‹é™çš„**åŸç†**éå¸¸ç›´è§‚ï¼šç¨‹åºç»“æ„ç›´æ¥åæ˜ äº†è¯­æ³•ç»“æ„ ([Recursive descent parser - Wikipedia](https://en.wikipedia.org/wiki/Recursive_descent_parser#:~:text=In%20computer%20science%20%2C%20a,2))ã€‚è§£æè¿‡ç¨‹ä»é¡¶å±‚è§„åˆ™å¼€å§‹ï¼Œé€çº§å‘ä¸‹å±•å¼€ï¼ŒæœŸæœ›è¾“å…¥ä¸²èƒ½åŒ¹é…æ‰€å±•å¼€çš„ç»ˆç»“ç¬¦åºåˆ—ã€‚å¦‚æœæŸä¸€æ­¥åŒ¹é…å¤±è´¥ï¼Œåˆ™å›æº¯åˆ°ä¸Šå±‚é€‰æ‹©è¯¥éç»ˆç»“ç¬¦çš„å¦ä¸€æ¡äº§ç”Ÿå¼é‡æ–°å°è¯•ã€‚è¿™ç§ç®—æ³•æ˜“äºæ‰‹å·¥ç¼–å†™å’Œç†è§£ï¼Œå› è€Œåœ¨æ—©æœŸè¯­è¨€è§£æï¼ˆå¦‚ç®€å•çš„è®¡ç®—å™¨è¯­æ³•ã€ç¼–è¯‘å™¨å‰ç«¯ï¼‰ä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚å¯¹äºæŸäº›å—é™çš„æ–‡æ³•ç±»åˆ«ï¼ˆä¾‹å¦‚LL(1)æ–‡æ³•ï¼Œæ²¡æœ‰å·¦é€’å½’ä¸”æ¯ä¸€æ­¥æ¨å¯¼å‡ç¡®å®šå”¯ä¸€è§„åˆ™ï¼‰ï¼Œé€’å½’ä¸‹é™ç”šè‡³å¯ä»¥åšåˆ°**é¢„æµ‹å¼è§£æ**ï¼Œæ— éœ€ä»»ä½•å›æº¯å³å¯çº¿æ€§æ—¶é—´å®Œæˆè§£æ ([Recursive descent parser - Wikipedia](https://en.wikipedia.org/wiki/Recursive_descent_parser#:~:text=A%20predictive%20parser%20is%20a,parser%20runs%20in%20%2070))ã€‚åœ¨è¿™ç§æœ€ä½³æƒ…å†µä¸‹ï¼Œé€’å½’ä¸‹é™è§£æçš„å¤æ‚åº¦æ¥è¿‘$O(n)$ï¼Œè€Œä¸”å®ç°ç®€å•ã€‚

ç„¶è€Œï¼Œå¯¹äºè‡ªç„¶è¯­è¨€è¿™æ ·å¤æ‚å’Œæ­§ä¹‰å¤§é‡å­˜åœ¨çš„æ–‡æ³•ï¼Œé€’å½’ä¸‹é™è§£æé¢ä¸´ä¸¥é‡æŒ‘æˆ˜ã€‚**ç¼ºç‚¹**ä¸»è¦åœ¨äºå›æº¯å’Œæ— é™å¾ªç¯çš„æ½œåœ¨é—®é¢˜ ([Recursive descent parser - Wikipedia](https://en.wikipedia.org/wiki/Recursive_descent_parser#:~:text=Recursive%20descent%20with%20backtracking%20is,backtracking%20may%20require%20%2072))ã€‚å¦‚æœæ–‡æ³•æ˜¯**äºŒä¹‰æ€§çš„**ï¼ˆambiguousï¼‰ï¼Œé€’å½’ä¸‹é™è§£æåœ¨æ²¡æœ‰æŒ‡å¯¼ç­–ç•¥ä¸‹ä¼šå°è¯•å¤šä¸ªè§„åˆ™ç»„åˆï¼Œå¯èƒ½å¯¼è‡´æŒ‡æ•°çº§çš„åˆ†æ”¯å°è¯•ï¼Œæ•ˆç‡å˜å¾—æä½ ([Recursive descent parser - Wikipedia](https://en.wikipedia.org/wiki/Recursive_descent_parser#:~:text=Recursive%20descent%20with%20backtracking%20is,backtracking%20may%20require%20%2072))ã€‚æ›´ç³Ÿçš„æ˜¯ï¼Œå¦‚æœæ–‡æ³•åŒ…å«**å·¦é€’å½’**ï¼ˆä¾‹å¦‚$A \to A\ \alpha$ï¼‰ï¼Œé€’å½’ä¸‹é™å°†é™·å…¥æ— é™é€’å½’å¾ªç¯è€Œæ— æ³•ç»ˆæ­¢ï¼Œé™¤éæˆ‘ä»¬å¯¹æ–‡æ³•è¿›è¡Œé¢„å¤„ç†æ¶ˆé™¤å·¦é€’å½’æˆ–åœ¨å®ç°ä¸Šå¢åŠ æ£€æŸ¥ã€‚æ­¤å¤–ï¼Œç°å®ä¸­çš„è‡ªç„¶è¯­è¨€æ–‡æ³•å¾€å¾€ä¸æ˜¯LL(k)æ–‡æ³•ï¼Œå…‰å‡­æœ‰é™å±•æœ›ç¬¦æ— æ³•å”¯ä¸€ç¡®å®šåº”ç”¨å“ªæ¡è§„åˆ™ï¼Œè¿™ä½¿å¾—ç®€å•çš„é¢„æµ‹å¼é€’å½’ä¸‹é™ä¸å¯ç”¨ï¼Œåªèƒ½ä¾èµ–å¤§é‡å›æº¯å°è¯•ï¼Œä»è€Œæå¤§æ‹–æ…¢è§£æé€Ÿåº¦ã€‚

ä¸ºå…‹æœä¸Šè¿°é—®é¢˜ï¼Œå®é™…çš„é€’å½’ä¸‹é™è§£æå™¨é€šå¸¸éœ€è¦è¿›è¡Œæ”¹è¿›ï¼šä¾‹å¦‚å¼•å…¥**é¢„æµ‹åˆ†æè¡¨**æˆ–**LL(1)åˆ†æ**ä»¥é¿å…å›æº¯ï¼Œæˆ–å€ŸåŠ©**å¤‡å¿˜å½•**ï¼ˆmemoizationï¼Œå½¢æˆè‡ªé¡¶å‘ä¸‹çš„chart parsingï¼Œå³Packratè§£æï¼‰æ¥é¿å…é‡å¤æ¢ç´¢åŒä¸€çŠ¶æ€ã€‚ä¸è¿‡è¿™äº›æ”¹è¿›å·²è¶…å‡ºæœ€æœ´ç´ é€’å½’ä¸‹é™çš„èŒƒç•´ã€‚åœ¨æ ‡å‡†é€’å½’ä¸‹é™ä¸­ï¼Œ**ä¼˜ç‚¹**æ˜¯ä»£ç ç»“æ„æ¸…æ™°ã€å®ç°æˆæœ¬ä½ï¼Œæ¯ä¸ªéç»ˆç»“ç¬¦çš„å¤„ç†é€»è¾‘ç›´è§‚ï¼›ä½†**ç¼ºç‚¹**æ˜¯åœ¨é¢å¯¹é€šç”¨CFGç”šè‡³è‡ªç„¶è¯­è¨€æ–‡æ³•æ—¶å¯èƒ½å‡ºç°æ— æ³•ç»ˆæ­¢æˆ–æŒ‡æ•°çº§è€—æ—¶çš„é—®é¢˜ ([Recursive descent parser - Wikipedia](https://en.wikipedia.org/wiki/Recursive_descent_parser#:~:text=Recursive%20descent%20with%20backtracking%20is,backtracking%20may%20require%20%2072))ã€‚å› æ­¤ï¼Œåœ¨NLPå®é™…åº”ç”¨ä¸­ï¼Œçº¯é€’å½’ä¸‹é™è§£æè¾ƒå°‘ç›´æ¥ä½¿ç”¨ï¼ˆé™¤éåœ¨å—æ§çš„å­è¯­è¨€æˆ–ç‰¹å®šè¯­æ³•ä¸‹ï¼‰ï¼Œæ›´å¤šæ˜¯ä½œä¸ºæ•™å­¦ç”¨é€”æˆ–ä¸å…¶ä»–æŠ€æœ¯ï¼ˆå¦‚é¢„æµ‹åˆ†æã€åŠ¨æ€è§„åˆ’ï¼‰ç»“åˆçš„æ–¹æ¡ˆã€‚

## åº”ç”¨åœºæ™¯ä¸æŒ‘æˆ˜

### åº”ç”¨åœºæ™¯

æˆåˆ†å¥æ³•åˆ†æä½œä¸ºæ­ç¤ºå¥å­ç»“æ„çš„å·¥å…·ï¼Œåœ¨è®¸å¤šè‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼š

- **æœºå™¨ç¿»è¯‘**ï¼šåœ¨åŸºäºè§„åˆ™æˆ–æ ‘åˆ°æ ‘çš„æœºå™¨ç¿»è¯‘ç³»ç»Ÿä¸­ï¼Œæºè¯­è¨€å¥å­çš„æˆåˆ†å¥æ³•æ ‘å¯ç”¨äºæŒ‡å¯¼ç¿»è¯‘è¿‡ç¨‹ã€‚è§£ææ ‘æ˜ç¡®äº†å¥å­çš„ä¸»å¹²å’Œå„ä¿®é¥°æˆåˆ†ï¼Œæœ‰åŠ©äºç¿»è¯‘ç³»ç»Ÿæ‰§è¡Œç»“æ„é‡æ’ã€å¯¹é½ç›¸åº”çŸ­è¯­ï¼Œä»¥åŠå¤„ç†æ­§ä¹‰çš„ç¿»è¯‘ã€‚åœ¨æ—©æœŸçš„ç»Ÿè®¡æœºå™¨ç¿»è¯‘ï¼ˆå¦‚åŸºäºçŸ­è¯­ç»“æ„æ ‘çš„ç¿»è¯‘æ¨¡å‹ï¼‰å’Œç°ä»£çš„ç¥ç»æœºå™¨ç¿»è¯‘ä¸­ï¼Œå¥æ³•ä¿¡æ¯éƒ½å¯ä»¥ç”¨äºæ”¹è¿›ç¿»è¯‘è´¨é‡ã€‚ä¾‹å¦‚ï¼Œå¥æ³•æ ‘å¯å¸®åŠ©ç³»ç»Ÿè¯†åˆ«å‡ºä¸»è¯­ã€å®¾è¯­ç­‰ï¼Œä»è€Œåœ¨ç¿»è¯‘æˆç›®æ ‡è¯­è¨€æ—¶è°ƒæ•´è¯åºï¼Œæ›´ç¬¦åˆç›®æ ‡è¯­è¨€çš„è¯­æ³•ä¹ æƒ¯ã€‚
    
- **é—®ç­”ç³»ç»Ÿ**ï¼šè‡ªåŠ¨é—®ç­”éœ€è¦æ·±åˆ»ç†è§£è‡ªç„¶è¯­è¨€é—®é¢˜çš„ç»“æ„ã€‚æˆåˆ†å¥æ³•åˆ†æå¯ä»¥å¸®åŠ©ç³»ç»Ÿè¯†åˆ«å‡ºé—®é¢˜å¥ä¸­çš„ç„¦ç‚¹å’Œé™å®šæ¡ä»¶ï¼Œå¦‚æ‰¾å‡ºä¸»è°“å®¾ç»“æ„ã€ä»å¥èŒƒå›´ç­‰ã€‚ä¾‹å¦‚åœ¨é—®å¥â€œWhat is the capital of the country that hosted the 2016 Olympics?â€ä¸­ï¼Œæˆåˆ†è§£æå¯ä»¥åŒºåˆ†ä¸»å¹²é—®é¢˜â€œæ˜¯ä»€ä¹ˆâ€ä»¥åŠé™å®šæ¡ä»¶â€œ2016å¹´å¥¥è¿ä¼šä¸»åŠå›½çš„é¦–éƒ½â€ï¼Œä»è€Œæœ‰åŠ©äºç³»ç»Ÿæå–æ­£ç¡®çš„ä¿¡æ¯æ¥ä½œç­”ã€‚é™¤äº†é—®é¢˜è§£æï¼Œå¥æ³•æ ‘åœ¨å¤„ç†æ–‡æœ¬èµ„æ–™ä»¥æå–ç­”æ¡ˆæ—¶ä¹Ÿæœ‰ç”¨å¤„â€”â€”é€šè¿‡è§£æå¥å­ï¼Œç³»ç»Ÿå¯ä»¥æ‰¾åˆ°æ½œåœ¨çš„ç­”æ¡ˆç‰‡æ®µï¼ˆå¦‚åè¯çŸ­è¯­ï¼‰å¹¶ç†è§£å®ƒä»¬ä¸é—®é¢˜çš„å…³ç³»ã€‚
    
- **ä¿¡æ¯æŠ½å–ä¸æ–‡æœ¬åˆ†æ**ï¼šåœ¨ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯çš„ä»»åŠ¡ä¸­ï¼ˆå¦‚ä»æ–°é—»ä¸­æå–äººç‰©-èŒä½å…³ç³»ï¼‰ï¼Œæˆåˆ†å¥æ³•æ ‘æä¾›äº†æ˜ç¡®çš„çŸ­è¯­è¾¹ç•Œå’Œä¿®é¥°å…³ç³»ä¿¡æ¯ã€‚æ¯”å¦‚ï¼Œä¸€ä¸ªå¥æ³•æ ‘å¯ä»¥å¸®åŠ©ç³»ç»Ÿç¡®å®šæŸäººåå¯¹åº”çš„å¤´è¡”çŸ­è¯­æˆ–æ‰€å±æœºæ„çŸ­è¯­ï¼Œè¿™å¯¹äºæ„å»ºçŸ¥è¯†å›¾è°±ç­‰éå¸¸å…³é”®ã€‚åˆå¦‚åœ¨æƒ…æ„Ÿåˆ†æä¸­ï¼Œä¸€äº›ç ”ç©¶åˆ©ç”¨å¥æ³•æ ‘å°†å¥å­é€’å½’åœ°æ˜ å°„åˆ°æƒ…æ„Ÿç©ºé—´ï¼ˆé€’å½’ç¥ç»ç½‘ç»œæ¨¡å‹ï¼‰ï¼Œå–å¾—æ¯”çº¯åºåˆ—æ¨¡å‹æ›´å¥½çš„æ•ˆæœ ([æˆåˆ†å¥æ³•åˆ†æç»¼è¿° - çŸ¥ä¹ä¸“æ ](https://zhuanlan.zhihu.com/p/45527481#:~:text=%E6%88%90%E5%88%86%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%8F%AF%E4%BB%A5%E5%88%A9%E7%94%A8%E5%88%B0%E8%AE%B8%E5%A4%9A%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E4%B8%AD%E5%8E%BB%EF%BC%8C%E6%AF%94%E5%A6%82%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E5%8F%AF%E4%BB%A5%E5%88%A9%E7%94%A8%E5%8F%A5%E5%AD%90%E7%9A%84%E6%88%90%E5%88%86%E5%8F%A5%E6%B3%95%E6%A0%91%E6%9D%A5%E8%BF%9B%E8%A1%8C%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%BB%BA%E6%A8%A1%EF%BC%8C%E4%BB%8E%E8%80%8C%E5%88%86%E6%9E%90%E5%87%BA%E5%8F%A5%E5%AD%90%E7%9A%84%E6%83%85%E6%84%9F%E3%80%82%20%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%88%A9%E7%94%A8%E5%9C%A8%E5%85%B6%E4%BB%96%E5%9F%BA%E7%A1%80%E4%BB%BB%20))ï¼ˆæ ‘ç»“æ„èƒ½æ›´å¥½åœ°æ•æ‰å¦å®šèŒƒå›´ã€ç¨‹åº¦å‰¯è¯ä½œç”¨åŸŸç­‰ï¼‰ã€‚
    

ä¸Šè¿°åªæ˜¯å‡ ä¸ªå…¸å‹åœºæ™¯ã€‚æ€»ä½“è€Œè¨€ï¼Œåªè¦æ˜¯éœ€è¦â€œç†è§£å¥å­ç»“æ„â€çš„NLPä»»åŠ¡ï¼Œéƒ½å¯ä»¥ä»æˆåˆ†å¥æ³•åˆ†æä¸­è·ç›Š ([æ·±å…¥è§£æSyntaxNetï¼šè‡ªç„¶è¯­è¨€ç†è§£çš„åˆ©å™¨-æ˜“æºAIèµ„è®¯ | ä¸‡ç»´æ˜“æº](https://www.showapi.com/news/article/66f80f104ddd79f11a397dd7#:~:text=%E9%99%85%E5%BA%94%E7%94%A8%E3%80%82%20,1%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E6%98%AF%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E4%B8%80%EF%BC%8C%E5%AE%83%E8%B4%9F%E8%B4%A3%E5%B0%86%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E6%88%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8F%AF%E4%BB%A5%E7%90%86%E8%A7%A3%E5%92%8C%E6%93%8D%E4%BD%9C%E7%9A%84%E5%BD%A2%E5%BC%8F%E3%80%82%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E9%80%9A%E8%BF%87%E5%AF%B9))ã€‚å¥æ³•ç»“æ„ä¸ºè¿›ä¸€æ­¥çš„è¯­ä¹‰ç†è§£æ‰“ä¸‹åŸºç¡€ï¼šè§£æå‡ºå¥æ³•æ ‘ä¹‹åï¼Œåç»­æ¨¡å—å¯ä»¥æ›´å‡†ç¡®åœ°æ‰§è¡Œè¯­ä¹‰è§’è‰²æ ‡æ³¨ï¼ˆè¯†åˆ«åŠ¨ä½œçš„æ–½äº‹ã€å—äº‹ç­‰ï¼‰æˆ–è€…æ ¸å¿ƒferenceè§£æç­‰ã€‚å¯ä»¥è¯´ï¼Œæˆåˆ†å¥æ³•åˆ†æåœ¨å¤æ‚çš„è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­æ‰®æ¼”ç€åº•å±‚æ”¯æ’‘è§’è‰²ï¼Œæ˜¯å®ç°æ·±å±‚è¯­è¨€ç†è§£ä¸å¯æˆ–ç¼ºçš„ä¸€ç¯ ([æ·±å…¥è§£æSyntaxNetï¼šè‡ªç„¶è¯­è¨€ç†è§£çš„åˆ©å™¨-æ˜“æºAIèµ„è®¯ | ä¸‡ç»´æ˜“æº](https://www.showapi.com/news/article/66f80f104ddd79f11a397dd7#:~:text=%E9%99%85%E5%BA%94%E7%94%A8%E3%80%82%20,1%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E6%98%AF%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E4%B8%80%EF%BC%8C%E5%AE%83%E8%B4%9F%E8%B4%A3%E5%B0%86%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E6%88%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8F%AF%E4%BB%A5%E7%90%86%E8%A7%A3%E5%92%8C%E6%93%8D%E4%BD%9C%E7%9A%84%E5%BD%A2%E5%BC%8F%E3%80%82%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E9%80%9A%E8%BF%87%E5%AF%B9))ã€‚

### æŒ‘æˆ˜

å°½ç®¡ç”¨é€”å¹¿æ³›ï¼Œæˆåˆ†å¥æ³•åˆ†ææœ¬èº«ä¹Ÿé¢ä¸´ä¸€äº›æŒ‘æˆ˜ï¼Œä¸»è¦åŒ…æ‹¬**æ­§ä¹‰**å’Œ**æ•ˆç‡**ä¸¤ä¸ªæ–¹é¢ï¼š

- **æ­§ä¹‰ï¼ˆAmbiguityï¼‰**ï¼šè‡ªç„¶è¯­è¨€å¥å­å¾€å¾€å­˜åœ¨å¤šç§è§£ææ–¹å¼ï¼Œäº§ç”Ÿä¸åŒçš„è¯­æ³•ç»“æ„ï¼Œå³**ç»“æ„æ­§ä¹‰**ã€‚ç»å…¸ä¾‹å­å¦‚â€œæˆ‘çœ‹åˆ°æˆ´ç€çœ¼é•œçš„è€äººâ€è¿™å¥è¯ï¼Œå¯èƒ½æœ‰ä¸¤ç§æˆåˆ†è§£æï¼šï¼ˆ1ï¼‰[æˆ‘ [çœ‹åˆ° [æˆ´ç€çœ¼é•œçš„è€äºº]]]ï¼Œï¼ˆ2ï¼‰[æˆ‘ [çœ‹åˆ° [æˆ´ç€çœ¼é•œ] çš„è€äºº]]ï¼Œå¯¹åº”ä¸åŒçš„å«ä¹‰ã€‚æˆåˆ†å¥æ³•åˆ†æå™¨åœ¨é¢å¯¹æ­§ä¹‰å¥å­æ—¶ï¼Œç†è®ºä¸Šä¼šç”Ÿæˆæ‰€æœ‰åˆæ³•çš„å¥æ³•æ ‘ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E5%9B%A0%E4%B8%BA%E6%AD%A7%E4%B9%89%EF%BC%8C%E4%B8%80%E4%B8%AA%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8F%AF%E8%83%BD%E6%9C%89%E5%A4%9A%E7%A7%8D%E6%8E%A8%E5%AF%BC%E6%96%B9%E6%B3%95%EF%BC%8C%E6%88%91%E4%BB%AC%E6%8A%8A%E6%89%80%E6%9C%89%E8%83%BD%E5%A4%9F%E6%8E%A8%E5%AF%BC%E5%AD%97%E7%AC%A6%E4%B8%B2s%E7%9A%84%E6%8E%A8%E5%AF%BC%E6%96%B9%E6%B3%95%E9%9B%86%E5%90%88%E8%AE%B0%E4%B8%BA%24%5Cmathcal))ã€‚å¤§é‡çš„æ­§ä¹‰ç»™ä¸‹æ¸¸å¤„ç†å¸¦æ¥å›°éš¾â€”â€”ç³»ç»Ÿéœ€è¦ä»å¯èƒ½çš„ç»“æ„ä¸­é€‰å‡ºæœ€ç¬¦åˆè¯­ä¹‰æˆ–ä¸Šä¸‹æ–‡çš„ä¸€ä¸ªã€‚å› æ­¤ï¼Œå¦‚ä½•æ¶ˆé™¤æ­§ä¹‰æˆ–é€‰æ‹©æœ€ä½³è§£ææ˜¯ä¸€å¤§æŒ‘æˆ˜ã€‚æ—©æœŸçš„åšæ³•æ˜¯é€šè¿‡**å¥æ³•è§„åˆ™çš„äººå·¥çº¦æŸ**ï¼ˆå¦‚å¥æ³•ä¼˜å…ˆçº§ï¼‰æ¥è£å‰ªä¸åˆç†çš„ç»“æ„ï¼›è€Œç°ä»£æ–¹æ³•ä¸»è¦ä¾èµ–**ç»Ÿè®¡æ¨¡å‹**æˆ–**æ¦‚ç‡ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•(PCFG)**ä¸ºæ¯æ£µæ ‘æ‰“åˆ†ï¼Œç„¶åé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„è§£ææ ‘ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E5%A6%82%E6%9E%9C%E4%B8%80%E4%B8%AA%E5%8F%A5%E5%AD%90%28%E5%AD%97%E7%AC%A6%E4%B8%B2%29%E6%98%AF%E6%9C%89%E6%AD%A7%E4%B9%89%E7%9A%84%EF%BC%8C%E9%82%A3%E4%B9%88%24%5Cvert%20%5Cmathcal%7BT%7D_G%28s%29%20%5Cvert%20,0%24%E3%80%82%E8%80%8CPCFG%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%E6%98%AF%E5%AF%B9%E4%BA%8EG%E7%9A%84%E6%89%80%E6%9C%89%E6%8E%A8%E5%AF%BCt%EF%BC%8C%E6%88%91%E4%BB%AC%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%EF%BC%8C%E4%BD%BF%E5%BE%97%EF%BC%9A)) ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%5C%5B%5Cunderset))ã€‚å³ä¾¿å¦‚æ­¤ï¼Œåœ¨é«˜åº¦æ­§ä¹‰çš„å¥å­ä¸­ï¼Œè§£æå™¨å¯èƒ½ä»ä¼šäº§ç”Ÿæ•°é‡åºå¤§çš„å€™é€‰æ ‘ï¼Œéœ€è¦é¢å¤–çš„è¯­ä¹‰æˆ–è¯­å¢ƒä¿¡æ¯æ‰èƒ½è¿›ä¸€æ­¥åˆ¤åˆ«ã€‚
    
- **æ•ˆç‡ï¼ˆEfficiencyï¼‰**ï¼šæˆåˆ†å¥æ³•åˆ†æåœ¨å¤æ‚åº¦ä¸Šæ˜¯ä¸€ä¸ªå¼€é”€è¾ƒé«˜çš„è¿‡ç¨‹ã€‚æ­£å¦‚å‰æ–‡æ‰€è¿°ï¼Œé€šç”¨çš„CFGè§£æç®—æ³•æœ€ä¼˜ä¹Ÿéœ€è¦$O(n^3)$æ—¶é—´ ([What is the CYK algorithm?](https://how.dev/answers/what-is-the-cyk-algorithm#:~:text=The%20running%20time%20of%20the,3))ã€‚å¯¹äºé•¿å¥æˆ–é•¿æ®µè½æ–‡æœ¬ï¼Œè§£æè€—æ—¶å’Œå†…å­˜å ç”¨éƒ½ä¼šæ˜¾è‘—å¢åŠ ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¦‚å®æ—¶çš„å¯¹è¯ç³»ç»Ÿæˆ–éœ€è¦å¤„ç†æµ·é‡æ–‡æœ¬çš„ç³»ç»Ÿï¼ˆæœç´¢å¼•æ“çš„é¢„å¤„ç†ç­‰ï¼‰ï¼Œé€å¥è§£æå¯èƒ½æˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚æ­¤å¤–ï¼Œè®­ç»ƒä¸€ä¸ªé«˜æ€§èƒ½çš„ç»Ÿè®¡è§£æå™¨æœ¬èº«ä¹Ÿéœ€è¦å¤§é‡æ ‡æ³¨å¥½çš„æ ‘åº“æ•°æ®ï¼ˆå¦‚Penn Treebankç­‰ï¼‰ï¼Œè·å¾—è¿™äº›æ•°æ®å’Œè®­ç»ƒæ¨¡å‹éƒ½ä»£ä»·ä¸è²ã€‚åœ¨å·¥ç¨‹å®ç°ä¸Šï¼Œè§£æå™¨éœ€è¦è€ƒè™‘è¯¸å¦‚ï¼šå¦‚ä½•ä¼˜åŒ–æ•°æ®ç»“æ„ï¼ˆä¾‹å¦‚ä½¿ç”¨å›¾ç®—æ³•å…±äº«å…¬å…±å­è§£æï¼‰ã€æ€æ ·å‰ªæå‡å°‘ä¸å¿…è¦çš„è®¡ç®—ã€ä»¥åŠå¦‚ä½•å¹¶è¡ŒåŒ–è§£æè¿‡ç¨‹ç­‰é—®é¢˜ã€‚å¦‚æœä½¿ç”¨ç¥ç»ç½‘ç»œæ–¹æ³•ï¼Œè¿˜éœ€è¦åº”å¯¹æ¨¡å‹æ¨ç†çš„æ•ˆç‡é—®é¢˜ã€‚æ€»ä¹‹ï¼Œæé«˜è§£ææ•ˆç‡æ—¢åŒ…æ‹¬ç®—æ³•å¤æ‚åº¦ä¸Šçš„æ”¹è¿›ï¼Œä¹ŸåŒ…æ‹¬å®ç°ä¸ç¡¬ä»¶å±‚é¢çš„ä¼˜åŒ–ã€‚åœ¨è¿½æ±‚å‡†ç¡®ç‡çš„åŒæ—¶ä¿æŒè§£æé€Ÿåº¦ï¼Œæ˜¯å¥æ³•åˆ†æåº”ç”¨ä¸­çš„æŒç»­æŒ‘æˆ˜ã€‚
    

é¢å¯¹ä»¥ä¸ŠæŒ‘æˆ˜ï¼Œç ”ç©¶è€…æå‡ºäº†å¤šç§åº”å¯¹ç­–ç•¥ã€‚ä¾‹å¦‚ï¼Œä¸ºè§£å†³æ­§ä¹‰ï¼Œ**æ¦‚ç‡æ¨¡å‹**å’Œ**æœºå™¨å­¦ä¹ **æ–¹æ³•è¢«å¹¿æ³›é‡‡ç”¨ï¼Œè®©æ¨¡å‹åŸºäºå¤§è§„æ¨¡è¯­æ–™è‡ªåŠ¨å­¦ä¹ æ­§ä¹‰æ¶ˆè§£çš„åå¥½ï¼ˆå¦‚åå¥½è¾ƒçŸ­ä¾å­˜è·ç¦»çš„ç»“æ„ç­‰)ã€‚å¯¹äºæ•ˆç‡é—®é¢˜ï¼Œåˆ™æœ‰**chart parsingä¼˜åŒ–**ï¼ˆå¦‚Earleyç®—æ³•åœ¨æŸäº›æƒ…å†µä¸‹æ¥è¿‘$O(n^2)$ï¼‰ã€**åˆ†å—è§£æ**ï¼ˆå°†é•¿å¥åˆ’åˆ†ä¸ºè¾ƒå°çš„ç‰‡æ®µè§£æåå†ç»„åˆï¼‰ã€ä»¥åŠè¿‘å¹´æ¥çš„**ç¥ç»ç½‘ç»œå¹¶è¡Œè®¡ç®—**ç­‰æ‰‹æ®µã€‚è¿™äº›åŠªåŠ›ä½¿å¾—æˆåˆ†å¥æ³•åˆ†æå™¨åœ¨ç²¾åº¦å’Œé€Ÿåº¦ä¸Šéƒ½æœ‰äº†æ˜¾è‘—æå‡ï¼Œä½†åœ¨å¼€æ”¾åŸŸå¤æ‚è¯­è¨€ä¸‹ï¼Œå®ç°å®æ—¶ä¸”é«˜ç²¾åº¦çš„å¥æ³•åˆ†æä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚

## å‘å±•ä¸å·¥å…·

æˆåˆ†å¥æ³•åˆ†æçš„æ–¹æ³•è®ºç»å†äº†ä»è§„åˆ™é©±åŠ¨åˆ°ç»Ÿè®¡å»ºæ¨¡å†åˆ°æ·±åº¦å­¦ä¹ çš„æ¼”è¿› ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%E5%8F%AF%E4%BB%A5%E5%88%86%E4%B8%BA%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%E3%80%81%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%E4%BB%A5%E5%8F%8A%E8%BF%91%E5%B9%B4%E6%9D%A5%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%96%B9%E6%B3%95%E7%AD%89%E3%80%82))ã€‚ä¸‹é¢æ¦‚è¿°å…¶å‘å±•å†ç¨‹ï¼Œå¹¶ä»‹ç»ä¸€äº›å…·æœ‰ä»£è¡¨æ€§çš„è§£æå·¥å…·ï¼š

- **è§„åˆ™å¼æ–¹æ³•**ï¼šæ—©æœŸçš„å¥æ³•åˆ†æç³»ç»Ÿå¤šåŸºäºäººå·¥ç¼–å†™çš„è§„åˆ™å’Œæ–‡æ³•ã€‚è¿™äº›ç³»ç»Ÿç”±è¯­è¨€å­¦å®¶æ‰‹å·¥æ’°å†™çŸ­è¯­ç»“æ„è§„åˆ™å’Œè§£æç­–ç•¥ï¼Œé€šè¿‡ç¼–ç å¤§é‡è¯­è¨€çŸ¥è¯†æ¥å¤„ç†å¥å­ã€‚å…¸å‹ä¾‹å­åŒ…æ‹¬åŸºäºè½¬æ¢æ–‡æ³•çš„è§£æå™¨å’Œä¸€äº›æ—©æœŸçš„ä¸“å®¶ç³»ç»Ÿã€‚è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯è§£æç»“æœå¯æ§ä¸”å…·å¯è§£é‡Šæ€§ï¼Œä½†ç¼ºç‚¹æ˜¯åœ¨åº”å¯¹è¯­è¨€çš„å¤šæ ·æ€§å’Œæ­§ä¹‰æ—¶åŠ›ä¸ä»å¿ƒâ€”â€”è§„åˆ™é›†æå…¶åºå¤§ä¸”ç»´æŠ¤å›°éš¾ï¼Œå¯¹æ–°åŸŸçš„é€‚åº”æ€§ä¹Ÿå·® ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%E5%8F%AF%E4%BB%A5%E5%88%86%E4%B8%BA%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%E3%80%81%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%E4%BB%A5%E5%8F%8A%E8%BF%91%E5%B9%B4%E6%9D%A5%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%96%B9%E6%B3%95%E7%AD%89%E3%80%82))ã€‚
    
- **ç»Ÿè®¡å¼æ–¹æ³•**ï¼š20ä¸–çºª90å¹´ä»£ä»¥æ¥ï¼Œéšç€æœ‰æ ‡æ³¨å¥æ³•æ ‘çš„æ ‘åº“ï¼ˆå¦‚Penn Treebankï¼‰çš„å»ºç«‹ï¼ŒåŸºäºæ•°æ®é©±åŠ¨çš„ç»Ÿè®¡è§£ææ–¹æ³•å–å¾—çªç ´ã€‚**æ¦‚ç‡ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•ï¼ˆPCFGï¼‰**æˆä¸ºè¿™ä¸€æ—¶æœŸçš„æ ¸å¿ƒæ¨¡å‹ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%EF%BC%9A%E5%85%B6%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF%E6%98%AF%E7%94%B1%E4%BA%BA%E5%B7%A5%E7%BB%84%E7%BB%87%E8%AF%AD%E6%B3%95%E8%A7%84%E5%88%99%EF%BC%8C%E5%BB%BA%E7%AB%8B%E8%AF%AD%E6%B3%95%E7%9F%A5%E8%AF%86%E5%BA%93%EF%BC%8C%E9%80%9A%E8%BF%87%E6%9D%A1%E4%BB%B6%E7%BA%A6%E6%9D%9F%E5%92%8C%E6%A3%80%E6%9F%A5%E6%9D%A5%E5%AE%9E%E7%8E%B0%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E6%AD%A7%E4%B9%89%E7%9A%84%E6%B6%88%E9%99%A4%E3%80%82))ã€‚PCFGä¸ºæ¯æ¡äº§ç”Ÿå¼é™„åŠ äº†ä¸€ä¸ªæ¦‚ç‡$P(\text{è§„åˆ™})$ï¼Œè¿™äº›æ¦‚ç‡å¯é€šè¿‡å·²æ ‡æ³¨çš„å¥æ³•æ ‘è¯­æ–™è¿›è¡Œä¼°è®¡ã€‚ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=,beta%24%E7%9A%84%E6%A6%82%E7%8E%87%E3%80%82))å½¢å¼åŒ–å®šä¹‰äº†PCFGï¼šåœ¨CFGåŸºç¡€ä¸Šï¼Œå¯¹äºæ–‡æ³•ä¸­æ¯ä¸ªè§„åˆ™$\alpha \to \beta$èµ‹äºˆæ¦‚ç‡$q(\alpha \to \beta)$ï¼Œå¹¶è¦æ±‚å¯¹ä»»ä¸€ç»™å®šå·¦ä¾§$\alpha$ï¼Œå…¶æ‰€æœ‰è§„åˆ™æ¦‚ç‡ä¹‹å’Œä¸º1 ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E6%A0%B9%E6%8D%AE%E6%A6%82%E7%8E%87%E7%9A%84%E5%AE%9A%E4%B9%89%EF%BC%8C%E5%AE%83%E9%9C%80%E8%A6%81%E6%BB%A1%E8%B6%B3%E5%A6%82%E4%B8%8B%E7%9A%84%E7%BA%A6%E6%9D%9F%EF%BC%9A))ã€‚è¿™æ ·ï¼Œä¸€ä¸ªå®Œæ•´æ¨å¯¼ï¼ˆæˆ–å¯¹åº”çš„å¥æ³•æ ‘)$t$çš„æ¦‚ç‡å¯å®šä¹‰ä¸ºæ‰€ç”¨è§„åˆ™æ¦‚ç‡çš„ä¹˜ç§¯ï¼š$p(t) = \prod_{i} q(\alpha_i \to \beta_i)$ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E6%9C%89%E4%BA%86%E4%B8%8A%E9%9D%A2%E7%9A%84%E5%AE%9A%E4%B9%89%EF%BC%8C%E4%B8%80%E7%A7%8D%E6%8E%A8%E5%AF%BC%E7%9A%84%E6%A6%82%E7%8E%87p))ã€‚æœ‰äº†PCFGï¼Œå°±å¯ä»¥é€šè¿‡**æ¦‚ç‡**æ¥åº¦é‡ä¸åŒè§£æçš„ä¼˜å…ˆçº§ï¼Œé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„æ ‘ä½œä¸ºæœ€ç»ˆç»“æœï¼Œå®ç°è‡ªåŠ¨æ­§ä¹‰æ¶ˆè§£ ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%E8%BF%99%E4%B8%AA%E4%BB%BB%E5%8A%A1%E7%9C%8B%E8%B5%B7%E6%9D%A5%E5%BE%88%E5%9B%B0%E9%9A%BE%EF%BC%8C%E5%9B%A0%E4%B8%BA%E4%B8%80%E4%B8%AA%E6%96%87%E6%B3%95G%E7%9A%84%E6%8E%A8%E5%AF%BC%E5%8F%AF%E8%83%BD%E6%9C%89%E6%97%A0%E7%A9%B7%E5%A4%9A%E4%B8%AA%EF%BC%8C%E5%AE%83%E4%BA%A7%E7%94%9F%E7%9A%84%E5%8F%A5%E5%AD%90%E5%8F%AF%E8%83%BD%E4%B9%9F%E6%9C%89%E6%97%A0%E7%A9%B7%E5%A4%9A%E4%B8%AA%E3%80%82%E4%BD%86%E6%98%AF%E9%80%9A%E8%BF%87%E4%B8%8B%E9%9D%A2%E7%9A%84%E4%BB%8B%E7%BB%8D%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BC%9A%E5%8F%91%E7%8E%B0%E8%BF%99%E4%B8%AA%E6%A6%82%E7%8E%87%E5%BE%88%E5%AE%B9%E6%98%93%E5%AE%9A%E4%B9%89%E3%80%82%E8%BF%99%E6%A0%B7%E7%9A%84%E6%A6%82%E7%8E%87%E5%8F%88%E6%9C%89%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8%20%E5%91%A2%EF%BC%9F%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E7%94%A8%E5%AE%83%E6%9D%A5%E6%B6%88%E9%99%A4%E6%AD%A7%E4%B9%89%EF%BC%8C%E6%AF%94%E5%A6%82%E4%B8%80%E4%B8%AA%E5%8F%A5%E5%AD%90s%E6%9C%89%E5%A4%9A%E7%A7%8D%E6%8E%A8%E5%AF%BC%EF%BC%8C%E9%82%A3%E4%B9%88%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E9%80%89%E6%8B%A9%E6%A6%82%E7%8E%87%E6%9C%80%E5%A4%A7%E7%9A%84%E9%82%A3%E4%B8%AA%E4%BD%9C%E4%B8%BAs%E7%9A%84%E6%8E%A8%E5%AF%BC%E3%80%82)) ([æˆåˆ†å¥æ³•åˆ†æ - æç†çš„åšå®¢](http://fancyerii.github.io/books/parser/#:~:text=%5C%5B%5Cunderset))ã€‚åŸºäºPCFGçš„è§£æå™¨åœ¨21ä¸–çºªåˆå¤§é‡æ¶Œç°ï¼Œå¦‚åŸºäºéè¯æ±‡åŒ–PCFGçš„**æ–¯å¦ç¦è§£æå™¨(Stanford Parser)**å’ŒåŸºäºè¯æ±‡åŒ–PCFGçš„**Collinsè§£æå™¨**ç­‰ã€‚è¿™äº›æ¨¡å‹åæ¥åˆæ‰©å±•å‡ºæ›´å¤æ‚çš„å˜ç§ï¼Œæ¯”å¦‚å¼•å…¥äº†è¯æ±‡ä¾èµ–çš„æ¦‚ç‡ï¼ˆè¯æ±‡åŒ–PCFGï¼‰ä»¥åŠä½¿ç”¨**æœ€å¤§ç†µæ¨¡å‹**ç»“åˆä¸Šä¸‹æ–‡ç‰¹å¾é€‰æ‹©è§„åˆ™ã€‚ç»Ÿè®¡å¼è§£æç›¸è¾ƒè§„åˆ™æ–¹æ³•æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼šå®ƒä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ ï¼Œèƒ½æ›´é²æ£’åœ°å¤„ç†æ­§ä¹‰å’Œè¦†ç›–å¹¿æ³›è¯­è¨€ç°è±¡ã€‚ä¸è¿‡ï¼Œç»Ÿè®¡æ¨¡å‹çš„è¡¨ç°é«˜åº¦ä¾èµ–è®­ç»ƒè¯­æ–™çš„è§„æ¨¡å’Œè´¨é‡ï¼Œå¯¹äºèµ„æºåŒ®ä¹è¯­è¨€å¯èƒ½æ•ˆæœå—é™ã€‚
    
- **ç¥ç»ç½‘ç»œæ–¹æ³•**ï¼šè¿›å…¥2010å¹´ä»£ï¼Œæ·±åº¦å­¦ä¹ åœ¨NLPé¢†åŸŸçš„æˆåŠŸä¹Ÿæ¨åŠ¨äº†å¥æ³•åˆ†ææŠ€æœ¯çš„å‘å±•ã€‚åŸºäºç¥ç»ç½‘ç»œçš„è§£æå™¨åˆ©ç”¨åˆ†å¸ƒå¼è¡¨ç¤ºå’Œç«¯åˆ°ç«¯å­¦ä¹ ï¼Œè¿›ä¸€æ­¥æé«˜äº†è§£æçš„å‡†ç¡®ç‡å’Œé€Ÿåº¦ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%E5%8F%AF%E4%BB%A5%E5%88%86%E4%B8%BA%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%E3%80%81%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%E4%BB%A5%E5%8F%8A%E8%BF%91%E5%B9%B4%E6%9D%A5%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%96%B9%E6%B3%95%E7%AD%89%E3%80%82))ã€‚ä¾‹å¦‚ï¼Œ**è¿ç§»ç®—æ³•**ï¼ˆtransition-basedï¼‰çš„è§£æå™¨å°†æ„å»ºå¥æ³•æ ‘çš„è¿‡ç¨‹è§†ä¸ºä¸€ç³»åˆ—åŠ¨ä½œåºåˆ—ï¼Œç”±å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰æˆ–Transformeræ¥é¢„æµ‹æ¯ä¸€æ­¥çš„æœ€ä¼˜åŠ¨ä½œï¼›**åŸºäºå›¾è¡¨**ï¼ˆchart-basedï¼‰çš„ç¥ç»è§£æå™¨åˆ™å€Ÿé‰´PCFGçš„åŠ¨æ€è§„åˆ’ç®—æ³•æ€æƒ³ï¼Œç”¨ç¥ç»ç½‘ç»œæ¥è¯„åˆ†æ‹†åˆ†ä½ç½®å’Œéç»ˆç»“ç¬¦é€‰æ‹©ã€‚åœ¨è¿™ä¸€é˜¶æ®µï¼Œå¤§é‡æ–°çš„æ¨¡å‹æ¶Œç°ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŒå‘LSTMç¼–ç å™¨çš„è§£æå™¨ã€åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„Chart Parserï¼Œä»¥åŠåˆ©ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆå¦‚BERTï¼‰çš„é«˜æ€§èƒ½è§£æå™¨ç­‰ã€‚è¿™äº›æ¨¡å‹åœ¨æ ‡å‡†è¯„æµ‹å¦‚Penn Treebankä¸Šå°†è§£æå‡†ç¡®ç‡æé«˜åˆ°äº†å‰æ‰€æœªæœ‰çš„é«˜åº¦ï¼ˆF1å€¼æ¥è¿‘95%æˆ–ä»¥ä¸Šï¼‰ã€‚ä¸ç»Ÿè®¡æ–¹æ³•ç›¸æ¯”ï¼Œç¥ç»æ–¹æ³•èƒ½æ›´å¥½åœ°æ•æ‰é•¿è·ç¦»ä¾èµ–å’Œå¤æ‚ç‰¹å¾ç»„åˆï¼Œä½†ä¹Ÿéœ€è¦æ›´å¤šè®­ç»ƒæ•°æ®ä¸”ç¼ºä¹ç›´æ¥çš„å¯è§£é‡Šæ€§ã€‚æ­¤å¤–ï¼Œä¸€äº›æœ€æ–°ç ”ç©¶å°è¯•èåˆç¥ç»ç½‘ç»œä¸æ˜¾å¼æ–‡æ³•çŸ¥è¯†ï¼Œä¾‹å¦‚**ç¥ç»PCFG**æ¨¡å‹ï¼Œå°†PCFGçš„ç»“æ„åŒ–ä¼˜ç‚¹ä¸ç¥ç»ç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ›ç›¸ç»“åˆï¼Œåœ¨æ— ç›‘ç£è§£æä»»åŠ¡ä¸­å–å¾—äº†è¿›å±•ã€‚
    

åœ¨å·¥å…·å±‚é¢ï¼Œå¦‚ä»Šæœ‰è®¸å¤šå¼€æºçš„æˆåˆ†å¥æ³•åˆ†æå™¨å¯ä¾›ä½¿ç”¨ï¼Œå…¶ä¸­ä½“ç°äº†ä¸Šè¿°å„ç§æ–¹æ³•ï¼š

- **Berkeley Parser**ï¼šç”±ä¼¯å…‹åˆ©å¤§å­¦NLPå°ç»„å¼€å‘çš„æˆåˆ†è§£æå™¨ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=2))ã€‚å®ƒåŸºäº**æ½œåœ¨å˜é‡PCFG**ï¼ˆå³åœ¨ä¼ ç»Ÿè¯­æ³•ç±»åˆ«ä¸Šå¼•å…¥ç»†ç²’åº¦çš„æ½œåœ¨å­ç±»åˆ«ä»¥æå‡ç²¾åº¦ï¼‰çš„æ–¹æ³•ï¼Œç”± Petrov ç­‰äººåœ¨2006å¹´å‰åæå‡ºã€‚Berkeley Parser èƒ½å¤Ÿä»æ ‘åº“è‡ªåŠ¨å­¦ä¹ ä¸€ä¸ªé«˜ç²¾åº¦çš„PCFGæ–‡æ³•ï¼Œåœ¨å½“æ—¶çš„è‹±æ–‡è§£æä»»åŠ¡ä¸Šå–å¾—äº†é¢†å…ˆæ€§èƒ½ã€‚ä½œä¸ºJavaç¼–å†™çš„å¼€æºå·¥å…·ï¼ŒBerkeley Parser å¯ä»¥æ”¯æŒç”¨æˆ·è®­ç»ƒè‡ªå®šä¹‰è¯­è¨€çš„æ¨¡å‹ï¼Œè‡³ä»Šä»è¢«ä½œä¸ºç»Ÿè®¡è§£æçš„ç»å…¸ä»£è¡¨ä¹‹ä¸€ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=2))ã€‚
    
- **Stanford Parser / Stanza**ï¼šæ–¯å¦ç¦å¤§å­¦å¼€å‘äº†è‘—åçš„ç»Ÿè®¡è§£æå™¨Stanford Parserï¼Œä»¥åŠè¿‘å¹´æ¨å‡ºçš„Pythonå·¥å…·åŒ…Stanzaã€‚æ—©æœŸçš„Stanford Parseråˆ©ç”¨è¯æ±‡åŒ–PCFGå’Œå­—ç¬¦è¯­è¨€æ¨¡å‹ç­‰å®ç°ï¼Œå¯¹è‹±æ–‡åŠå¤šç§è¯­è¨€æä¾›äº†è‰¯å¥½çš„è§£ææ€§èƒ½ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=1))ã€‚å…¶åç»§è€…Stanzaåˆ™åœ¨åº•å±‚é‡‡ç”¨äº†æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼ŒåŒ…å«é¢„è®­ç»ƒçš„å¤šè¯­è¨€æˆåˆ†å¥æ³•åˆ†ææ¨¡å‹ã€‚Stanzaåˆ©ç”¨åŒå‘LSTMå’Œä¼˜åŒ–çš„è®­ç»ƒç­–ç•¥ï¼Œå¤§å¹…æå‡äº†é€Ÿåº¦ï¼ŒåŒæ—¶å€ŸåŠ©GPUå®ç°é«˜å¹¶å‘è§£æã€‚æ–¯å¦ç¦çš„å·¥å…·å¹¿æ³›ç”¨äºç ”ç©¶å’Œå·¥ä¸šåº”ç”¨ï¼Œç‰¹ç‚¹æ˜¯æ˜“ç”¨ä¸”æ”¯æŒå¤šè¯­è¨€ï¼›ç”¨æˆ·åªéœ€è°ƒç”¨ç›¸åº”æ¥å£ï¼Œå³å¯è·å¾—å¥æ³•æ ‘è¾“å‡ºã€‚
    
- **SyntaxNet (Google)**ï¼šè°·æ­Œäº2016å¹´å¼€æºçš„è‡ªç„¶è¯­è¨€è§£ææ¡†æ¶ï¼Œè‘—åçš„æ¨¡å‹**Parsey McParseface**å°±åŸºäºæ­¤ ([è°·æ­Œå¼€æºæœ€ç²¾ç¡®è‡ªç„¶è¯­è¨€è§£æå™¨SyntaxNet | æœºå™¨ä¹‹å¿ƒ](https://www.jiqizhixin.com/articles/2016-05-14#:~:text=%E8%B0%B7%E6%AD%8C%E5%BC%80%E6%BA%90%E6%9C%80%E7%B2%BE%E7%A1%AE%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E8%A7%A3%E6%9E%90%E5%99%A8SyntaxNet))ã€‚SyntaxNetä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œå’ŒæŸæœç´¢ç­‰æŠ€æœ¯ï¼Œå®ç°äº†æ¥è¿‘ä¸“å®¶æ°´å‡†çš„è‹±æ–‡è§£æå‡†ç¡®åº¦ï¼ˆå…¬å¸ƒçš„è‹±æ–‡ä¾å­˜è§£æå‡†ç¡®ç‡çº¦94% ([è°·æ­Œå¼€æºæœ€ç²¾ç¡®è‡ªç„¶è¯­è¨€è§£æå™¨SyntaxNet | æœºå™¨ä¹‹å¿ƒ](https://www.jiqizhixin.com/articles/2016-05-14#:~:text=%E9%87%8D%E6%96%B0%E8%8E%B7%E5%8F%96%E5%8F%A5%E5%AD%90%E8%AF%AD%E8%AF%8D%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB%20%EF%BC%8C%E6%AD%A3%E7%A1%AE%E7%8E%87%E8%BE%BE94%25%E3%80%82%E8%BF%99%E4%B8%AA%E6%88%90%E7%BB%A9%E4%B8%8D%E4%BB%85%E5%A5%BD%E4%BA%8E%E5%85%AC%E5%8F%B8%E4%B9%8B%E5%89%8D%E7%9A%84%E6%9C%80%E5%A5%BD%E6%88%90%E7%BB%A9%EF%BC%8C%E4%B9%9F%E5%87%BB%E8%B4%A5%E4%BA%86%E4%B9%8B%E5%89%8D%E4%BB%BB%E4%BD%95%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95%E3%80%82%E5%B0%BD%E7%AE%A1%E8%BF%98%E6%B2%A1%E6%9C%89%E8%BF%99%E6%96%B9%E9%9D%A2%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B0%E5%A6%82%E4%BD%95%E7%9A%84%E7%A0%94%E7%A9%B6%E6%96%87%E7%8C%AE%EF%BC%8C%E4%BD%86%E6%98%AF%EF%BC%8C%E4%BB%8E%20%E5%85%AC%E5%8F%B8%E5%86%85%E9%83%A8%E7%9A%84%E6%B3%A8%E9%87%8A%E9%A1%B9%E7%9B%AE%E9%82%A3%E9%87%8C%EF%BC%8C%E7%A0%94%E7%A9%B6%E4%BA%BA%E5%91%98%E5%BE%97%E7%9F%A5%EF%BC%8C%E5%8F%97%E8%BF%87%E8%BF%99%E6%96%B9%E9%9D%A2%E8%AE%AD%E7%BB%83%E7%9A%84%E8%AF%AD%E8%A8%80%E5%AD%A6%E5%AE%B6%E5%88%86%E6%9E%90%E5%87%86%E7%A1%AE%E7%8E%87%E4%B8%BA96))ï¼‰ã€‚è™½ç„¶SyntaxNetæœ¬è´¨ä¸Šæ˜¯ä¾å­˜è§£æå™¨ï¼Œä½†å…¶æ¡†æ¶åŒæ ·å¯ä»¥ç”¨äºç”Ÿæˆæˆåˆ†å¥æ³•æ ‘ã€‚å®ƒé€šè¿‡ç¥ç»ç½‘ç»œæ¨¡å‹å­¦ä¹ è½¬ç§»æ“ä½œåºåˆ—ï¼Œå®ç°å¯¹å¥å­çš„å¿«é€Ÿåˆ†æ ([è°·æ­Œå¼€æºæœ€ç²¾ç¡®è‡ªç„¶è¯­è¨€è§£æå™¨SyntaxNet | æœºå™¨ä¹‹å¿ƒ](https://www.jiqizhixin.com/articles/2016-05-14#:~:text=,Parsey%20McParseface%E3%80%82%E9%99%A4%E4%BA%86%E8%AE%A9%E6%9B%B4%E5%A4%9A%E4%BA%BA%E4%BD%BF%E7%94%A8%E5%88%B0%E6%9C%80%E5%85%88%E8%BF%9B%E7%9A%84%E5%88%86%E6%9E%90%E6%8A%80%E6%9C%AF%E4%B9%8B%E5%A4%96%EF%BC%8C%E8%BF%99%E6%AC%A1%E5%BC%80%E6%BA%90%E4%B8%BE%E6%8E%AA%E4%B9%9F%E6%9C%89%E5%88%A9%E4%BA%8E%E5%85%AC%E5%8F%B8%E5%80%9F%E5%8A%A9%E7%A4%BE%E5%8C%BA%E5%8A%9B%E9%87%8F%E5%8A%A0%E5%BF%AB%E8%A7%A3%E5%86%B3%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%90%86%E8%A7%A3%E9%9A%BE%E9%A2%98%E7%9A%84%E6%AD%A5%E4%BC%90%EF%BC%8C%E6%83%A0%E5%8F%8A%E8%B0%B7%E6%AD%8C%E4%B8%9A%E5%8A%A1%E3%80%82))ã€‚SyntaxNetçš„å‡ºç°æ ‡å¿—ç€å·¥ä¸šç•Œå¯¹é«˜ç²¾åº¦å¥æ³•åˆ†æçš„é‡è§†ï¼Œå…¶å¼€æºä¹ŸåŠ é€Ÿäº†ç›¸å…³æŠ€æœ¯çš„æ™®åŠã€‚ä¸è¿‡ï¼Œç”±äºéœ€è¦å¤æ‚çš„é…ç½®å’Œè®¡ç®—èµ„æºï¼Œåæ¥æ›´ç®€æ˜“çš„å·¥å…·ï¼ˆå¦‚åŸºäºTensorFlowæˆ–PyTorchçš„è½»é‡çº§è§£æå™¨ï¼‰é€æ¸æˆä¸ºä¸»æµã€‚
    

æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€äº›å€¼å¾—ä¸€æçš„è§£æå·¥å…·ä¸åº“ï¼Œä¾‹å¦‚**AllenNLP**æä¾›äº†é¢„è®­ç»ƒçš„æˆåˆ†è§£ææ¨¡å‹ï¼Œ**spaCy**é›†æˆäº†é«˜æ•ˆçš„ä¾å­˜è§£æï¼ˆä¸æ”¯æŒæˆåˆ†æ ‘ï¼Œä½†å¯ä»¥é€šè¿‡è½¬åŒ–è·å–ï¼‰ï¼Œä»¥åŠ**NTLK**ç­‰æ•™ç ”ç”¨é€”çš„åº“åŒ…å«åŸºç¡€çš„è§£æç®—æ³•å®ç°ç­‰ã€‚è¿™äº›å·¥å…·å„æœ‰ä¾§é‡ï¼Œä½†æ€»ä½“è¶‹åŠ¿æ˜¯èµ°å‘ç¥ç»ç½‘ç»œå®ç°ã€è¿½æ±‚æ›´é«˜å‡†ç¡®ç‡ä¸æ›´å¿«è§£æé€Ÿåº¦ï¼Œå¹¶æ”¯æŒå¤šè¯­è¨€å’Œæ˜“ç”¨çš„æ¥å£ã€‚

ç»¼ä¸Šï¼Œæˆåˆ†å¥æ³•åˆ†æé¢†åŸŸä»æ—©æœŸåŸºäºè§„åˆ™çš„äººå·¥æ–¹æ³•ï¼Œå‘å±•åˆ°ç»Ÿè®¡å­¦ä¹ ä¸»å¯¼ï¼Œå†åˆ°å¦‚ä»Šç¥ç»æ¨¡å‹ç››è¡Œï¼Œä½“ç°äº†NLPæŠ€æœ¯æ•´ä½“æ¼”è¿›çš„ç¼©å½±ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œè§£æå™¨çš„æ€§èƒ½ï¼ˆå‡†ç¡®ç‡å’Œæ•ˆç‡ï¼‰ä¸æ–­æå‡ï¼Œåº”ç”¨èŒƒå›´ä¹Ÿè¶Šæ¥è¶Šå¹¿ã€‚ä½†æ— è®ºåº•å±‚æŠ€æœ¯å¦‚ä½•å˜åŒ–ï¼Œæˆåˆ†å¥æ³•åˆ†æçš„æ ¸å¿ƒç›®æ ‡å§‹ç»ˆä¸å˜ï¼š**æ­ç¤ºå¥å­çš„çŸ­è¯­ç»“æ„ï¼Œå¸®åŠ©æœºå™¨æ›´å¥½åœ°â€œçœ‹æ‡‚â€äººç±»è¯­è¨€çš„å¥å­**ã€‚å±•æœ›æœªæ¥ï¼Œéšç€æ›´å¼ºå¤§çš„è¯­è¨€æ¨¡å‹å’Œæ›´å¤šè·¨é¢†åŸŸçŸ¥è¯†çš„å¼•å…¥ï¼Œå¥æ³•åˆ†æå™¨æœ‰æœ›å˜å¾—æ›´åŠ æ™ºèƒ½å’Œå®ç”¨ï¼Œä¸ºè‡ªç„¶è¯­è¨€ç†è§£æä¾›æ›´åŠ æœ‰åŠ›çš„æ”¯æŒã€‚ ([ä¸€æ–‡äº†è§£æˆåˆ†å¥æ³•åˆ†æ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/1423828#:~:text=%E5%8F%A5%E6%B3%95%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%E5%8F%AF%E4%BB%A5%E5%88%86%E4%B8%BA%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%E3%80%81%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%E4%BB%A5%E5%8F%8A%E8%BF%91%E5%B9%B4%E6%9D%A5%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%96%B9%E6%B3%95%E7%AD%89%E3%80%82)) ([æ·±å…¥è§£æSyntaxNetï¼šè‡ªç„¶è¯­è¨€ç†è§£çš„åˆ©å™¨-æ˜“æºAIèµ„è®¯ | ä¸‡ç»´æ˜“æº](https://www.showapi.com/news/article/66f80f104ddd79f11a397dd7#:~:text=%E9%99%85%E5%BA%94%E7%94%A8%E3%80%82%20,1%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%20%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E6%98%AF%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E7%BB%84%E4%BB%B6%E4%B9%8B%E4%B8%80%EF%BC%8C%E5%AE%83%E8%B4%9F%E8%B4%A3%E5%B0%86%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%96%87%E6%9C%AC%E8%BD%AC%E6%8D%A2%E6%88%90%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8F%AF%E4%BB%A5%E7%90%86%E8%A7%A3%E5%92%8C%E6%93%8D%E4%BD%9C%E7%9A%84%E5%BD%A2%E5%BC%8F%E3%80%82%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%E9%80%9A%E8%BF%87%E5%AF%B9))