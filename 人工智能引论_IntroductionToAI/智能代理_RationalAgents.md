

> [!caution] 
> 📌 本文内容由 ChatGPT 生成，供学习与参考使用。


# 智能代理_RationalAgents

本章介绍智能 Agent 的基本概念、其与环境之间的关系、理性行为的评估方式、环境的性质，以及 Agent 的结构形式，为理解人工智能系统的运行逻辑和设计原则奠定基础。

---

## 2.1 Agent 和环境

智能体（Agent）是一个能够感知环境并做出相应行动的实体。

### 🌐 Agent 的定义
Agent 是任何能够通过感知其环境并采取行动来实现目标的系统。

### 👁️ Agent 的核心组成
- **传感器（Sensors）**：用于接收环境输入。
- **效应器（Actuators）**：用于对环境施加影响。
- **Agent 程序**：决定在不同感知下采取何种行为的算法或规则。

### 🔁 感知-行动 循环（Perception-Action Cycle）
1. 感知环境
2. 处理输入
3. 选择行动
4. 执行动作
5. 影响环境

### 🧠 示例
| Agent 类型 | 传感器 | 效应器 | 环境 |
|------------|---------|--------|------|
| 扫地机器人 | 碰撞感应器、摄像头 | 电动马达、吸尘装置 | 房间地面 |
| 自动驾驶汽车 | 雷达、摄像头、GPS | 方向盘、油门、刹车 | 道路交通环境 |

---

## 2.2 好的行为：理性的概念

一个 Agent 是否“智能”，核心在于其是否**理性**。

### ✅ 理性 Agent 的定义
> 在给定的感知、知识、目标和资源约束下，始终选择最有利于达成目标的行为。

### 🧮 行为好坏的标准
- **性能度量（Performance Measure）**：定义行为是否成功。
- **感知历史（Percept Sequence）**：Agent 对环境的全部观测。
- **知识（Knowledge）**：Agent 已知的世界模型。
- **可能的行动集（Actions）**：Agent 所能执行的所有行为。

### 📊 实际案例
AlphaGo 下棋时并不总是追求“吃子”而是追求“赢局”——这是理性而非贪婪。

---

## 2.3 环境的性质

Agent 的设计高度依赖于所处环境的特性。

### 🔍 环境分类维度
| 维度 | 说明 | 示例 |
|------|------|------|
| 可观察性 | 全可观察 / 部分可观察 | 国际象棋 vs. 打牌 |
| 决定性 | 行动结果是否确定 | 数学运算 vs. 骰子掷点 |
| 动态性 | 环境是否随时间变化 | 静态图像识别 vs. 实时对战 |
| 离散性 | 状态是否离散 | 棋盘 vs. 自然语言 |
| Agent 数量 | 单 Agent vs. 多 Agent | 迷宫机器人 vs. 多车协同调度 |

### 🏗️ 环境建模方法
- 状态空间模型
- 马尔可夫决策过程（MDP）
- 图搜索结构

---

## 2.4 Agent 的结构

根据任务复杂度不同，Agent 的内部结构也各异。

### 🔧 Agent 类型

#### 1. 简单反射 Agent（Simple Reflex Agent）
- 基于当前感知选择行为
- 不考虑历史
- 优点：简单快速
- 缺点：缺乏记忆与推理能力
- eg. `if-then` 结构

#### 2. 模型驱动 Agent（Model-Based Agent）
- 内部维护环境模型
- 可处理部分可观察环境

#### 3. 目标导向 Agent（Goal-Based Agent）
- 除了模型外还具有目标状态
- 能够规划路径

#### 4. 实用性导向 Agent（Utility-Based Agent）
- 不仅有目标，还考虑**偏好与效用**
- 可用于选择“最优”解而非“可行”解

### 🧱 Agent 架构 vs. Agent 程序
- **Agent 架构**：硬件与模块组织结构
- **Agent 程序**：运行在架构上的软件逻辑

---

